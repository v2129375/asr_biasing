{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/v2129375/asr_biasing\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/v2129375/anaconda3/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:590: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "/root/.cache/huggingface/modules/transformers_modules/microsoft/Phi-4-multimodal-instruct/33e62acdd07cd7d6635badd529aa0a3467bb9c6a/speech_conformer_encoder.py:2774: FutureWarning: Please specify CheckpointImpl.NO_REENTRANT as CheckpointImpl.REENTRANT will soon be removed as the default and eventually deprecated.\n",
      "  lambda i: encoder_checkpoint_wrapper(\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:00<00:00,  5.87it/s]\n",
      "Train dataset size: 1311\n",
      "Eval dataset size: 200\n",
      "Intent categories: ['city', 'music', 'video']\n",
      "training on 1 GPUs\n",
      "running eval:   0%|                                     | 0/200 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/v2129375/anaconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "running eval: 100%|███████████████████████████| 200/200 [00:19<00:00, 10.45it/s]\n",
      "/home/v2129375/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/v2129375/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/v2129375/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Accuracy: 0.6250\n",
      "F1 Score: 0.5948\n",
      "/home/v2129375/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/v2129375/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/v2129375/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "                                                                           precision    recall  f1-score   support\n",
      "\n",
      "                                                            Output: music       0.00      0.00      0.00         0\n",
      "                                                            Output: video       0.00      0.00      0.00         0\n",
      "To solve this task, I would need to process the audio file and transcribe       0.00      0.00      0.00         0\n",
      "                                                                     city       1.00      0.88      0.93        65\n",
      "                                                                    music       0.45      1.00      0.62        53\n",
      "                                                                    video       1.00      0.18      0.31        82\n",
      "\n",
      "                                                                 accuracy                           0.62       200\n",
      "                                                                macro avg       0.41      0.34      0.31       200\n",
      "                                                             weighted avg       0.85      0.62      0.59       200\n",
      "\n",
      "Accuracy before finetuning: 0.625\n",
      "F1 Score before finetuning: 0.5947616541494574\n",
      "  0%|                                                  | 0/1311 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/v2129375/anaconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "{'loss': 6.5661, 'grad_norm': 95.5, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.01}\n",
      "{'loss': 1.4061, 'grad_norm': 1.9296875, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.02}\n",
      "{'loss': 0.4298, 'grad_norm': 38.75, 'learning_rate': 2.4e-05, 'epoch': 0.02}   \n",
      "{'loss': 0.1895, 'grad_norm': 0.00897216796875, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.03}\n",
      "{'loss': 0.5653, 'grad_norm': 3.890625, 'learning_rate': 4e-05, 'epoch': 0.04}  \n",
      "{'loss': 0.634, 'grad_norm': 0.10205078125, 'learning_rate': 3.968279143536876e-05, 'epoch': 0.05}\n",
      "{'loss': 0.5187, 'grad_norm': 0.220703125, 'learning_rate': 3.936558287073751e-05, 'epoch': 0.05}\n",
      "{'loss': 0.1531, 'grad_norm': 0.0556640625, 'learning_rate': 3.904837430610627e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0036, 'grad_norm': 0.0015869140625, 'learning_rate': 3.873116574147502e-05, 'epoch': 0.07}\n",
      "{'loss': 1.1251, 'grad_norm': 0.0047607421875, 'learning_rate': 3.841395717684378e-05, 'epoch': 0.08}\n",
      "{'loss': 0.2946, 'grad_norm': 6.0, 'learning_rate': 3.809674861221253e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0212, 'grad_norm': 0.0025482177734375, 'learning_rate': 3.7779540047581286e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0341796875, 'learning_rate': 3.7462331482950045e-05, 'epoch': 0.1}\n",
      "{'loss': 0.2447, 'grad_norm': 0.0008544921875, 'learning_rate': 3.71451229183188e-05, 'epoch': 0.11}\n",
      "{'loss': 0.2084, 'grad_norm': 0.0014190673828125, 'learning_rate': 3.682791435368755e-05, 'epoch': 0.11}\n",
      "{'loss': 0.0, 'grad_norm': 0.000560760498046875, 'learning_rate': 3.651070578905631e-05, 'epoch': 0.12}\n",
      "{'loss': 0.4095, 'grad_norm': 0.004608154296875, 'learning_rate': 3.619349722442506e-05, 'epoch': 0.13}\n",
      "{'loss': 0.0785, 'grad_norm': 0.060302734375, 'learning_rate': 3.587628865979382e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0, 'grad_norm': 0.044677734375, 'learning_rate': 3.555908009516257e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0197, 'grad_norm': 0.0004711151123046875, 'learning_rate': 3.524187153053133e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0, 'grad_norm': 0.0005340576171875, 'learning_rate': 3.492466296590008e-05, 'epoch': 0.16}\n",
      "{'loss': 1.5846, 'grad_norm': 39.25, 'learning_rate': 3.460745440126884e-05, 'epoch': 0.17}\n",
      "{'loss': 0.001, 'grad_norm': 0.01165771484375, 'learning_rate': 3.429024583663759e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0007, 'grad_norm': 0.010498046875, 'learning_rate': 3.3973037272006345e-05, 'epoch': 0.18}\n",
      "{'loss': 0.3293, 'grad_norm': 0.00090789794921875, 'learning_rate': 3.3655828707375104e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0159, 'grad_norm': 0.00384521484375, 'learning_rate': 3.333862014274386e-05, 'epoch': 0.2}\n",
      "{'loss': 0.0001, 'grad_norm': 0.02685546875, 'learning_rate': 3.302141157811261e-05, 'epoch': 0.21}\n",
      "{'loss': 0.0713, 'grad_norm': 0.00058746337890625, 'learning_rate': 3.270420301348137e-05, 'epoch': 0.21}\n",
      "{'loss': 0.2753, 'grad_norm': 0.0026397705078125, 'learning_rate': 3.238699444885012e-05, 'epoch': 0.22}\n",
      "{'loss': 0.3348, 'grad_norm': 0.0004749298095703125, 'learning_rate': 3.206978588421888e-05, 'epoch': 0.23}\n",
      "{'loss': 0.0188, 'grad_norm': 0.00041961669921875, 'learning_rate': 3.175257731958763e-05, 'epoch': 0.24}\n",
      "{'loss': 0.0009, 'grad_norm': 0.0013275146484375, 'learning_rate': 3.1435368754956386e-05, 'epoch': 0.24}\n",
      "{'loss': 0.0122, 'grad_norm': 0.0011138916015625, 'learning_rate': 3.111816019032514e-05, 'epoch': 0.25}\n",
      "{'loss': 0.2167, 'grad_norm': 81.0, 'learning_rate': 3.08009516256939e-05, 'epoch': 0.26}\n",
      "{'loss': 0.209, 'grad_norm': 0.00482177734375, 'learning_rate': 3.048374306106265e-05, 'epoch': 0.27}\n",
      "{'loss': 0.134, 'grad_norm': 0.00046539306640625, 'learning_rate': 3.0166534496431407e-05, 'epoch': 0.27}\n",
      "{'loss': 0.0002, 'grad_norm': 0.0004634857177734375, 'learning_rate': 2.9849325931800163e-05, 'epoch': 0.28}\n",
      "{'loss': 0.2761, 'grad_norm': 0.0419921875, 'learning_rate': 2.953211736716892e-05, 'epoch': 0.29}\n",
      "{'loss': 0.3944, 'grad_norm': 43.25, 'learning_rate': 2.921490880253767e-05, 'epoch': 0.3}\n",
      "{'loss': 0.4461, 'grad_norm': 0.004913330078125, 'learning_rate': 2.8897700237906425e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0, 'grad_norm': 0.00482177734375, 'learning_rate': 2.858049167327518e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0023, 'grad_norm': 0.000865936279296875, 'learning_rate': 2.8263283108643937e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0004, 'grad_norm': 0.00104522705078125, 'learning_rate': 2.794607454401269e-05, 'epoch': 0.33}\n",
      "{'loss': 0.001, 'grad_norm': 0.0006103515625, 'learning_rate': 2.7628865979381445e-05, 'epoch': 0.34}\n",
      "{'loss': 0.0001, 'grad_norm': 0.00023365020751953125, 'learning_rate': 2.73116574147502e-05, 'epoch': 0.34}\n",
      "{'loss': 0.1097, 'grad_norm': 0.00119781494140625, 'learning_rate': 2.6994448850118958e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0003, 'grad_norm': 0.000583648681640625, 'learning_rate': 2.667724028548771e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0, 'grad_norm': 0.00031280517578125, 'learning_rate': 2.6360031720856466e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0, 'grad_norm': 0.00012969970703125, 'learning_rate': 2.6042823156225222e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0012, 'grad_norm': 0.00012874603271484375, 'learning_rate': 2.572561459159398e-05, 'epoch': 0.38}\n",
      "{'loss': 0.3876, 'grad_norm': 0.037841796875, 'learning_rate': 2.5408406026962728e-05, 'epoch': 0.39}\n",
      "{'loss': 0.4013, 'grad_norm': 0.0020751953125, 'learning_rate': 2.5091197462331484e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0023, 'grad_norm': 0.00189208984375, 'learning_rate': 2.477398889770024e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0005, 'grad_norm': 0.00019931793212890625, 'learning_rate': 2.4456780333068996e-05, 'epoch': 0.41}\n",
      "{'loss': 0.0795, 'grad_norm': 0.0002651214599609375, 'learning_rate': 2.413957176843775e-05, 'epoch': 0.42}\n",
      "{'loss': 0.0018, 'grad_norm': 2.5, 'learning_rate': 2.3822363203806505e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0024, 'grad_norm': 0.00010156631469726562, 'learning_rate': 2.350515463917526e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0, 'grad_norm': 0.000293731689453125, 'learning_rate': 2.3187946074544017e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0, 'grad_norm': 0.0004863739013671875, 'learning_rate': 2.287073750991277e-05, 'epoch': 0.45}\n",
      "{'loss': 0.4418, 'grad_norm': 0.00031280517578125, 'learning_rate': 2.2553528945281525e-05, 'epoch': 0.46}\n",
      "{'loss': 0.0, 'grad_norm': 0.000286102294921875, 'learning_rate': 2.223632038065028e-05, 'epoch': 0.47}\n",
      "{'loss': 0.0, 'grad_norm': 0.00020694732666015625, 'learning_rate': 2.1919111816019037e-05, 'epoch': 0.47}\n",
      "{'loss': 0.2334, 'grad_norm': 0.000270843505859375, 'learning_rate': 2.1601903251387787e-05, 'epoch': 0.48}\n",
      "{'loss': 0.1951, 'grad_norm': 0.041748046875, 'learning_rate': 2.1284694686756543e-05, 'epoch': 0.49}\n",
      "{'loss': 0.2917, 'grad_norm': 0.00170135498046875, 'learning_rate': 2.09674861221253e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0, 'grad_norm': 0.00014400482177734375, 'learning_rate': 2.0650277557494055e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0141, 'grad_norm': 0.0002956390380859375, 'learning_rate': 2.0333068992862808e-05, 'epoch': 0.51}\n",
      "{'loss': 0.0483, 'grad_norm': 21.75, 'learning_rate': 2.0015860428231564e-05, 'epoch': 0.52}\n",
      "{'loss': 0.0007, 'grad_norm': 0.00022983551025390625, 'learning_rate': 1.969865186360032e-05, 'epoch': 0.53}\n",
      "{'loss': 0.0, 'grad_norm': 0.0001201629638671875, 'learning_rate': 1.9381443298969072e-05, 'epoch': 0.53}\n",
      "{'loss': 0.1835, 'grad_norm': 0.00010204315185546875, 'learning_rate': 1.906423473433783e-05, 'epoch': 0.54}\n",
      "{'loss': 0.7625, 'grad_norm': 0.000774383544921875, 'learning_rate': 1.8747026169706585e-05, 'epoch': 0.55}\n",
      "{'loss': 0.0, 'grad_norm': 0.001953125, 'learning_rate': 1.8429817605075337e-05, 'epoch': 0.56}\n",
      "{'loss': 0.2835, 'grad_norm': 0.060546875, 'learning_rate': 1.8112609040444093e-05, 'epoch': 0.56}\n",
      "{'loss': 0.5878, 'grad_norm': 0.0009307861328125, 'learning_rate': 1.7795400475812846e-05, 'epoch': 0.57}\n",
      "{'loss': 0.102, 'grad_norm': 0.0006561279296875, 'learning_rate': 1.7478191911181602e-05, 'epoch': 0.58}\n",
      "{'loss': 0.0001, 'grad_norm': 0.006317138671875, 'learning_rate': 1.7160983346550358e-05, 'epoch': 0.59}\n",
      "{'loss': 0.0019, 'grad_norm': 1.078125, 'learning_rate': 1.6843774781919114e-05, 'epoch': 0.59}\n",
      "{'loss': 0.0034, 'grad_norm': 0.0003871917724609375, 'learning_rate': 1.6526566217287867e-05, 'epoch': 0.6}\n",
      "{'loss': 0.4334, 'grad_norm': 51.75, 'learning_rate': 1.6209357652656623e-05, 'epoch': 0.61}\n",
      "{'loss': 0.0, 'grad_norm': 0.00579833984375, 'learning_rate': 1.5892149088025375e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0232, 'grad_norm': 0.007110595703125, 'learning_rate': 1.557494052339413e-05, 'epoch': 0.63}\n",
      "{'loss': 0.3009, 'grad_norm': 0.01348876953125, 'learning_rate': 1.5257731958762888e-05, 'epoch': 0.63}\n",
      "{'loss': 0.0002, 'grad_norm': 0.0018310546875, 'learning_rate': 1.4940523394131644e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0004, 'grad_norm': 0.10107421875, 'learning_rate': 1.4623314829500396e-05, 'epoch': 0.65}\n",
      "{'loss': 0.1672, 'grad_norm': 0.02197265625, 'learning_rate': 1.4306106264869152e-05, 'epoch': 0.66}\n",
      "{'loss': 0.0001, 'grad_norm': 0.40625, 'learning_rate': 1.3988897700237907e-05, 'epoch': 0.66}\n",
      "{'loss': 0.0, 'grad_norm': 0.0003986358642578125, 'learning_rate': 1.3671689135606663e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0, 'grad_norm': 0.000244140625, 'learning_rate': 1.3354480570975417e-05, 'epoch': 0.68}\n",
      "{'loss': 0.0, 'grad_norm': 0.00323486328125, 'learning_rate': 1.3037272006344173e-05, 'epoch': 0.69}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0002593994140625, 'learning_rate': 1.2720063441712926e-05, 'epoch': 0.69}\n",
      "{'loss': 0.0785, 'grad_norm': 0.0003147125244140625, 'learning_rate': 1.2402854877081682e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0001, 'grad_norm': 0.000270843505859375, 'learning_rate': 1.2085646312450436e-05, 'epoch': 0.71}\n",
      "{'loss': 0.3585, 'grad_norm': 0.0001392364501953125, 'learning_rate': 1.1768437747819192e-05, 'epoch': 0.72}\n",
      "{'loss': 0.0, 'grad_norm': 0.00024318695068359375, 'learning_rate': 1.1451229183187947e-05, 'epoch': 0.72}\n",
      "{'loss': 0.0141, 'grad_norm': 0.000354766845703125, 'learning_rate': 1.1134020618556703e-05, 'epoch': 0.73}\n",
      "{'loss': 0.0068, 'grad_norm': 0.0263671875, 'learning_rate': 1.0816812053925455e-05, 'epoch': 0.74}\n",
      "{'loss': 0.0, 'grad_norm': 0.0036773681640625, 'learning_rate': 1.0499603489294211e-05, 'epoch': 0.75}\n",
      "{'loss': 0.0, 'grad_norm': 0.028564453125, 'learning_rate': 1.0182394924662966e-05, 'epoch': 0.76}\n",
      "{'loss': 0.3669, 'grad_norm': 0.000148773193359375, 'learning_rate': 9.865186360031722e-06, 'epoch': 0.76}\n",
      "{'loss': 0.038, 'grad_norm': 0.0002536773681640625, 'learning_rate': 9.547977795400476e-06, 'epoch': 0.77}\n",
      "{'loss': 0.0069, 'grad_norm': 0.0001773834228515625, 'learning_rate': 9.230769230769232e-06, 'epoch': 0.78}\n",
      "{'loss': 0.0, 'grad_norm': 0.0002593994140625, 'learning_rate': 8.913560666137987e-06, 'epoch': 0.79}\n",
      "{'loss': 0.1587, 'grad_norm': 0.033203125, 'learning_rate': 8.596352101506743e-06, 'epoch': 0.79}\n",
      "{'loss': 0.0001, 'grad_norm': 0.00014781951904296875, 'learning_rate': 8.279143536875495e-06, 'epoch': 0.8}\n",
      "{'loss': 0.134, 'grad_norm': 0.0008697509765625, 'learning_rate': 7.961934972244251e-06, 'epoch': 0.81}\n",
      "{'loss': 0.1097, 'grad_norm': 0.00023174285888671875, 'learning_rate': 7.644726407613006e-06, 'epoch': 0.82}\n",
      "{'loss': 0.0086, 'grad_norm': 7.0, 'learning_rate': 7.327517842981761e-06, 'epoch': 0.82}\n",
      "{'loss': 0.0015, 'grad_norm': 0.000827789306640625, 'learning_rate': 7.010309278350515e-06, 'epoch': 0.83}\n",
      "{'loss': 0.0021, 'grad_norm': 0.0003337860107421875, 'learning_rate': 6.693100713719271e-06, 'epoch': 0.84}\n",
      "{'loss': 0.0066, 'grad_norm': 0.00022792816162109375, 'learning_rate': 6.375892149088026e-06, 'epoch': 0.85}\n",
      "{'loss': 0.0, 'grad_norm': 0.000919342041015625, 'learning_rate': 6.05868358445678e-06, 'epoch': 0.85}\n",
      "{'loss': 0.0021, 'grad_norm': 0.00038909912109375, 'learning_rate': 5.741475019825535e-06, 'epoch': 0.86}\n",
      "{'loss': 0.0192, 'grad_norm': 0.0001850128173828125, 'learning_rate': 5.424266455194291e-06, 'epoch': 0.87}\n",
      "{'loss': 0.0, 'grad_norm': 0.000701904296875, 'learning_rate': 5.107057890563045e-06, 'epoch': 0.88}\n",
      "{'loss': 0.0196, 'grad_norm': 0.000911712646484375, 'learning_rate': 4.789849325931801e-06, 'epoch': 0.88}\n",
      "{'loss': 0.3919, 'grad_norm': 0.00037384033203125, 'learning_rate': 4.472640761300555e-06, 'epoch': 0.89}\n",
      "{'loss': 0.0001, 'grad_norm': 0.00017642974853515625, 'learning_rate': 4.1554321966693106e-06, 'epoch': 0.9}\n",
      "{'loss': 0.0001, 'grad_norm': 0.00014400482177734375, 'learning_rate': 3.838223632038066e-06, 'epoch': 0.91}\n",
      "{'loss': 0.0785, 'grad_norm': 0.00104522705078125, 'learning_rate': 3.5210150674068206e-06, 'epoch': 0.92}\n",
      "{'loss': 0.0004, 'grad_norm': 0.0002040863037109375, 'learning_rate': 3.2038065027755754e-06, 'epoch': 0.92}\n",
      "{'loss': 0.0, 'grad_norm': 0.000171661376953125, 'learning_rate': 2.8865979381443297e-06, 'epoch': 0.93}\n",
      "{'loss': 0.1918, 'grad_norm': 0.00012969970703125, 'learning_rate': 2.569389373513085e-06, 'epoch': 0.94}\n",
      "{'loss': 0.134, 'grad_norm': 9.870529174804688e-05, 'learning_rate': 2.25218080888184e-06, 'epoch': 0.95}\n",
      "{'loss': 0.0007, 'grad_norm': 0.00604248046875, 'learning_rate': 1.934972244250595e-06, 'epoch': 0.95}\n",
      "{'loss': 0.0, 'grad_norm': 0.00025177001953125, 'learning_rate': 1.61776367961935e-06, 'epoch': 0.96}\n",
      "{'loss': 0.1022, 'grad_norm': 13.3125, 'learning_rate': 1.300555114988105e-06, 'epoch': 0.97}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0002651214599609375, 'learning_rate': 9.833465503568597e-07, 'epoch': 0.98}\n",
      "{'loss': 0.0001, 'grad_norm': 0.000148773193359375, 'learning_rate': 6.661379857256146e-07, 'epoch': 0.98}\n",
      "{'loss': 0.1507, 'grad_norm': 0.000186920166015625, 'learning_rate': 3.489294210943696e-07, 'epoch': 0.99}\n",
      "{'loss': 0.0, 'grad_norm': 0.00019073486328125, 'learning_rate': 3.1720856463124506e-08, 'epoch': 1.0}\n",
      "{'train_runtime': 265.927, 'train_samples_per_second': 4.93, 'train_steps_per_second': 4.93, 'train_loss': 0.1879370804749083, 'epoch': 1.0}\n",
      "100%|███████████████████████████████████████| 1311/1311 [04:25<00:00,  4.93it/s]\n",
      "/home/v2129375/anaconda3/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:590: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n",
      "/root/.cache/huggingface/modules/transformers_modules/speech_conformer_encoder.py:2774: FutureWarning: Please specify CheckpointImpl.NO_REENTRANT as CheckpointImpl.REENTRANT will soon be removed as the default and eventually deprecated.\n",
      "  lambda i: encoder_checkpoint_wrapper(\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:00<00:00,  5.70it/s]\n",
      "running eval:   0%|                                     | 0/200 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/v2129375/anaconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "running eval: 100%|███████████████████████████| 200/200 [00:17<00:00, 11.23it/s]\n",
      "Accuracy: 0.9450\n",
      "F1 Score: 0.9453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        city       0.98      0.95      0.97        65\n",
      "       music       0.89      0.94      0.92        53\n",
      "       video       0.95      0.94      0.94        82\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.94      0.95      0.94       200\n",
      "weighted avg       0.95      0.94      0.95       200\n",
      "\n",
      "Accuracy after finetuning: 0.945\n",
      "F1 Score after finetuning: 0.94532497924523\n"
     ]
    }
   ],
   "source": [
    "!/home/v2129375/anaconda3/bin/python /home/v2129375/asr_biasing/intent/finetune_phi4/sample_finetune_speech_intent.py \\\n",
    "    --use_flash_attention "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
