{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/v2129375/asr_biasing\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始执行第 1/3 次微调任务\n",
      "参数: num_sentences=200, output_dir=asr/model/200aishell1p2keywords\n",
      "执行命令: python /home/v2129375/asr_biasing/asr/aishell_finetune/finetune_aishell_keywords.py --num_sentences 200 --output_dir asr/model/200aishell1p2keywords\n",
      "/home/v2129375/miniconda3/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:590: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "使用GPU: [0, 1]\n",
      "/home/v2129375/.cache/huggingface/modules/transformers_modules/microsoft/Phi-4-multimodal-instruct/33e62acdd07cd7d6635badd529aa0a3467bb9c6a/speech_conformer_encoder.py:2774: FutureWarning: Please specify CheckpointImpl.NO_REENTRANT as CheckpointImpl.REENTRANT will soon be removed as the default and eventually deprecated.\n",
      "  lambda i: encoder_checkpoint_wrapper(\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "警告: 数据集中没有发现'source'列。在RANDOMIZE_DOMAIN=True时将随机分配领域。\n",
      "Loaded 555 keywords for video domain\n",
      "Loaded 390 keywords for music domain\n",
      "Loaded 930 keywords for city domain\n",
      "可用的领域: ['video', 'music', 'city']\n",
      "随机选择了 200 条语句进行训练，原始数据集大小: 120098\n",
      "Train dataset size: 200\n",
      "Keywords directory: data/catslu\n",
      "Use keywords: True\n",
      "Using all available keywords for each domain\n",
      "Random sentences selection: enabled (training with 200 sentences)\n",
      "Domain randomization: enabled (randomly assigning domains to training samples)\n",
      "training on 2 GPUs\n",
      "[2025-06-02 20:47:12,170] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "  0%|                                                   | 0/200 [00:00<?, ?it/s]Domain randomization enabled. Randomly assigning domains from: ['video', 'music', 'city']Domain randomization enabled. Randomly assigning domains from: ['video', 'music', 'city']\n",
      "\n",
      "Domain randomization enabled. Randomly assigning domains from: ['video', 'music', 'city']\n",
      "Domain randomization enabled. Randomly assigning domains from: ['video', 'music', 'city']\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/v2129375/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "{'loss': 2.4902, 'grad_norm': 67.5, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.05}\n",
      "{'loss': 0.769, 'grad_norm': 22.375, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.1}\n",
      "{'loss': 0.1278, 'grad_norm': 27.75, 'learning_rate': 2.4e-05, 'epoch': 0.15}   \n",
      "{'loss': 0.0174, 'grad_norm': 2.78125, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.2}\n",
      "{'loss': 0.0153, 'grad_norm': 0.029296875, 'learning_rate': 4e-05, 'epoch': 0.25}\n",
      "{'loss': 0.0812, 'grad_norm': 0.34375, 'learning_rate': 3.733333333333334e-05, 'epoch': 0.3}\n",
      "{'loss': 0.2923, 'grad_norm': 0.12353515625, 'learning_rate': 3.466666666666667e-05, 'epoch': 0.35}\n",
      "{'loss': 0.4991, 'grad_norm': 0.013916015625, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.4}\n",
      "{'loss': 0.2229, 'grad_norm': 0.98046875, 'learning_rate': 2.9333333333333333e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0871, 'grad_norm': 3.515625, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0972, 'grad_norm': 3.203125, 'learning_rate': 2.4e-05, 'epoch': 0.55}\n",
      "{'loss': 0.1405, 'grad_norm': 0.109375, 'learning_rate': 2.1333333333333335e-05, 'epoch': 0.6}\n",
      "{'loss': 0.1439, 'grad_norm': 0.006866455078125, 'learning_rate': 1.866666666666667e-05, 'epoch': 0.65}\n",
      "{'loss': 0.2779, 'grad_norm': 20.0, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0623, 'grad_norm': 8.75, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.75}\n",
      "{'loss': 0.1201, 'grad_norm': 0.0517578125, 'learning_rate': 1.0666666666666667e-05, 'epoch': 0.8}\n",
      "{'loss': 0.0068, 'grad_norm': 0.27734375, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.85}\n",
      "{'loss': 0.3109, 'grad_norm': 0.039306640625, 'learning_rate': 5.333333333333334e-06, 'epoch': 0.9}\n",
      "{'loss': 0.1104, 'grad_norm': 0.11181640625, 'learning_rate': 2.666666666666667e-06, 'epoch': 0.95}\n",
      "{'loss': 0.3421, 'grad_norm': 11.5625, 'learning_rate': 0.0, 'epoch': 1.0}      \n",
      "{'train_runtime': 244.9124, 'train_samples_per_second': 0.817, 'train_steps_per_second': 0.817, 'train_loss': 0.3107197903841734, 'epoch': 1.0}\n",
      "100%|█████████████████████████████████████████| 200/200 [04:04<00:00,  1.22s/it]\n",
      "Training completed successfully!\n",
      "第 1/3 次微调任务完成\n",
      "\n",
      "使用关键词: True\n",
      "使用所有可用的关键词\n",
      "使用GPU: [0, 1]\n",
      "/home/v2129375/miniconda3/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:590: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "正在加载模型到{'model.embed_tokens': 0, 'model.embed_dropout': 0, 'model.embed_tokens_extend': 0, 'lm_head': 0, 'model.layers.0': 1, 'model.layers.1': 1, 'model.layers.2': 1, 'model.layers.3': 1, 'model.layers.4': 1, 'model.layers.5': 1, 'model.layers.6': 1, 'model.layers.7': 1, 'model.layers.8': 1, 'model.layers.9': 1, 'model.layers.10': 1, 'model.layers.11': 1, 'model.layers.12': 1, 'model.layers.13': 1, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 1, 'model.layers.17': 1, 'model.layers.18': 1, 'model.layers.19': 1, 'model.layers.20': 1, 'model.layers.21': 1, 'model.layers.22': 1, 'model.layers.23': 1, 'model.layers.24': 1, 'model.layers.25': 1, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1}...\n",
      "/home/v2129375/miniconda3/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:590: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n",
      "/home/v2129375/.cache/huggingface/modules/transformers_modules/200aishell1p2keywords/speech_conformer_encoder.py:2774: FutureWarning: Please specify CheckpointImpl.NO_REENTRANT as CheckpointImpl.REENTRANT will soon be removed as the default and eventually deprecated.\n",
      "  lambda i: encoder_checkpoint_wrapper(\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "模型分布情况:\n",
      "  model.embed_tokens: 0\n",
      "  model.embed_dropout: 0\n",
      "  model.embed_tokens_extend: 0\n",
      "  lm_head: 0\n",
      "  model.layers.0: 1\n",
      "  model.layers.1: 1\n",
      "  model.layers.2: 1\n",
      "  model.layers.3: 1\n",
      "  model.layers.4: 1\n",
      "  model.layers.5: 1\n",
      "  model.layers.6: 1\n",
      "  model.layers.7: 1\n",
      "  model.layers.8: 1\n",
      "  model.layers.9: 1\n",
      "  model.layers.10: 1\n",
      "  model.layers.11: 1\n",
      "  model.layers.12: 1\n",
      "  model.layers.13: 1\n",
      "  model.layers.14: 1\n",
      "  model.layers.15: 1\n",
      "  model.layers.16: 1\n",
      "  model.layers.17: 1\n",
      "  model.layers.18: 1\n",
      "  model.layers.19: 1\n",
      "  model.layers.20: 1\n",
      "  model.layers.21: 1\n",
      "  model.layers.22: 1\n",
      "  model.layers.23: 1\n",
      "  model.layers.24: 1\n",
      "  model.layers.25: 1\n",
      "  model.layers.26: 1\n",
      "  model.layers.27: 1\n",
      "  model.layers.28: 1\n",
      "  model.layers.29: 1\n",
      "  model.layers.30: 1\n",
      "  model.layers.31: 1\n",
      "  model.norm: 1\n",
      "Loaded 555 keywords for video domain\n",
      "Loaded 390 keywords for music domain\n",
      "Loaded 930 keywords for city domain\n",
      "处理音频:   0%|                                         | 0/378 [00:00<?, ?it/s]/home/v2129375/asr_biasing/asr/phi4_keywords.py:212: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "/home/v2129375/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "处理音频: 100%|███████████████████████████████| 378/378 [04:56<00:00,  1.28it/s]\n",
      "\n",
      "开始评估ASR结果...\n",
      "\n",
      "错误识别的样本:\n",
      "原始文本: 红日\n",
      "识别结果: 同日\n",
      "关键词: 红日\n",
      "---\n",
      "原始文本: 十万个为什么\n",
      "识别结果: 问个为什么\n",
      "关键词: 十万个为什么\n",
      "---\n",
      "原始文本: 你想看哪一个非凡公主\n",
      "识别结果: 快提快提快提快提快提快提快提快提快提快提快提快提快提快提快提快提快提快提快提快提快提快提快提快提快提\n",
      "关键词: 非凡公主\n",
      "---\n",
      "原始文本: 我想看楚乔传\n",
      "识别结果: 我想看处巧传\n",
      "关键词: 楚乔传\n",
      "---\n",
      "原始文本: 猪小妹\n",
      "识别结果: 朱小妹\n",
      "关键词: 猪小妹\n",
      "---\n",
      "原始文本: 我想看汪汪队\n",
      "识别结果: 我想看旺旺队\n",
      "关键词: 汪汪队\n",
      "---\n",
      "原始文本: 播放艾利之书\n",
      "识别结果: 播放安利之书\n",
      "关键词: 艾利之书\n",
      "---\n",
      "原始文本: 我要看千与千寻\n",
      "识别结果: 我要看千里寻秦\n",
      "关键词: 千与千寻\n",
      "---\n",
      "原始文本: 我要看天线宝宝宝宝\n",
      "识别结果: 妈我要看天线宝宝\n",
      "关键词: 天线宝宝宝宝\n",
      "---\n",
      "原始文本: 播放猩球崛起三\n",
      "识别结果: 播放星球大战三\n",
      "关键词: 猩球崛起三\n",
      "---\n",
      "原始文本: 世上只有妈妈好\n",
      "识别结果: 四川只有慢慢好\n",
      "关键词: 世上只有妈妈好\n",
      "---\n",
      "原始文本: 播放艾利之书\n",
      "识别结果: 播放爱丽丝之书\n",
      "关键词: 艾利之书\n",
      "---\n",
      "原始文本: 小飞侠\n",
      "识别结果: 小飞象玩过那个那个飞机\n",
      "关键词: 小飞侠\n",
      "---\n",
      "原始文本: 放白雪公主\n",
      "识别结果: 放白鞋公主\n",
      "关键词: 白雪公主\n",
      "---\n",
      "原始文本: 放小白兔白又白\n",
      "识别结果: 唱一下白兔白兔\n",
      "关键词: 小白兔白又白\n",
      "---\n",
      "原始文本: 钱塘老娘舅\n",
      "识别结果: 前唐老娘舅\n",
      "关键词: 钱塘老娘舅\n",
      "---\n",
      "原始文本: 播放超级会飞侠第三季\n",
      "识别结果: 播放超级灰飞侠第三季\n",
      "关键词: 超级会飞侠\n",
      "---\n",
      "原始文本: 放粉红猪小妹第二十二集\n",
      "识别结果: 放粉红猪做小妹第二十二集\n",
      "关键词: 粉红猪小妹\n",
      "---\n",
      "原始文本: 播放巧虎来啦\n",
      "识别结果: 播放巧虎来了\n",
      "关键词: 巧虎来啦\n",
      "---\n",
      "原始文本: 请放一首张明敏的我的中国心\n",
      "识别结果: 请放一首张艺玲的我的中国心\n",
      "关键词: 张明敏\n",
      "---\n",
      "原始文本: 唱小蓓蕾儿儿歌\n",
      "识别结果: 唱小贝勒儿歌\n",
      "关键词: 小蓓蕾\n",
      "---\n",
      "原始文本: 梦然唱的没有你陪伴真的好孤单\n",
      "识别结果: 梦来唱的没有你陪伴真的好孤单\n",
      "关键词: 梦然\n",
      "---\n",
      "原始文本: 云菲菲的都市情缘\n",
      "识别结果: 云飞飞的都市情缘\n",
      "关键词: 云菲菲\n",
      "---\n",
      "原始文本: 祁隆的歌爰的世界只有你\n",
      "识别结果: 启龙的歌爱的世界只有你\n",
      "关键词: 祁隆\n",
      "---\n",
      "原始文本: 樊竹青的歌曲\n",
      "识别结果: 樊州青的歌曲\n",
      "关键词: 樊竹青\n",
      "---\n",
      "原始文本: 唱一首王蓉的小鸡小鸡\n",
      "识别结果: 唱一首方文的小鸡小鸡\n",
      "关键词: 王蓉\n",
      "---\n",
      "原始文本: 潘玮柏的\n",
      "识别结果: 听潘伟博的\n",
      "关键词: 潘玮柏\n",
      "---\n",
      "原始文本: 张宇的一言难尽\n",
      "识别结果: 章鱼的一言难尽\n",
      "关键词: 张宇\n",
      "---\n",
      "原始文本: 黄蓉小鸡小鸡\n",
      "识别结果: 黄龙小鸡小鸡\n",
      "关键词: 黄蓉\n",
      "---\n",
      "原始文本: 汪苏泷那个男孩\n",
      "识别结果: 公主龙那个人男孩\n",
      "关键词: 汪苏泷\n",
      "---\n",
      "原始文本: 来一首王绎龙的摇摆哥\n",
      "识别结果: 来一首王毅龙的摇摆歌\n",
      "关键词: 王绎龙\n",
      "---\n",
      "原始文本: 小乐明天杭州天气怎么样\n",
      "识别结果: 小乐明天安江的天气怎么样\n",
      "关键词: 杭州\n",
      "---\n",
      "原始文本: 鄂州\n",
      "识别结果: 我们走了\n",
      "关键词: 鄂州\n",
      "---\n",
      "原始文本: 嗯现在深深圳天气怎么样\n",
      "识别结果: 韩红\n",
      "关键词: 深深圳\n",
      "---\n",
      "原始文本: 北京后天的天气怎么样\n",
      "识别结果: 三十三\n",
      "关键词: 北京\n",
      "---\n",
      "原始文本: 我要看兰州天气\n",
      "识别结果: 我要看南通的天气\n",
      "关键词: 兰州\n",
      "---\n",
      "原始文本: 阜新今天天气\n",
      "识别结果: 抚新今天天气\n",
      "关键词: 阜新\n",
      "---\n",
      "原始文本: 绥化\n",
      "识别结果: 谁话\n",
      "关键词: 绥化\n",
      "---\n",
      "原始文本: 长沙后天的天气\n",
      "识别结果: 查查后天的天气\n",
      "关键词: 长沙\n",
      "---\n",
      "原始文本: 亳州的天气怎么样\n",
      "识别结果: 灰姑娘幻影忍者三毛流浪记赌霸恭喜发财唱歌小白兔上灯台偷油吃下不来小毛驴白又白小毛兔上灯台小白兔小白兔\n",
      "关键词: 亳州\n",
      "---\n",
      "\n",
      "总体结果:\n",
      "CER: 0.1187\n",
      "Keyword WER: 0.1058\n",
      "\n",
      "各类别结果:\n",
      "\n",
      "类别: video\n",
      "样本数: 157\n",
      "CER: 0.1301\n",
      "Keyword WER: 0.1210\n",
      "\n",
      "类别: music\n",
      "样本数: 101\n",
      "CER: 0.0708\n",
      "Keyword WER: 0.1188\n",
      "\n",
      "类别: city\n",
      "样本数: 120\n",
      "CER: 0.1441\n",
      "Keyword WER: 0.0750\n",
      "\n",
      "结果已保存到: asr/exp/new.json\n",
      "第 1/3 次评估完成\n",
      "\n",
      "开始执行第 2/3 次微调任务\n",
      "参数: num_sentences=500, output_dir=asr/model/500aishell1p2keywords\n",
      "执行命令: python /home/v2129375/asr_biasing/asr/aishell_finetune/finetune_aishell_keywords.py --num_sentences 500 --output_dir asr/model/500aishell1p2keywords\n",
      "/home/v2129375/miniconda3/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:590: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "使用GPU: [0, 1]\n",
      "/home/v2129375/.cache/huggingface/modules/transformers_modules/microsoft/Phi-4-multimodal-instruct/33e62acdd07cd7d6635badd529aa0a3467bb9c6a/speech_conformer_encoder.py:2774: FutureWarning: Please specify CheckpointImpl.NO_REENTRANT as CheckpointImpl.REENTRANT will soon be removed as the default and eventually deprecated.\n",
      "  lambda i: encoder_checkpoint_wrapper(\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "警告: 数据集中没有发现'source'列。在RANDOMIZE_DOMAIN=True时将随机分配领域。\n",
      "Loaded 555 keywords for video domain\n",
      "Loaded 390 keywords for music domain\n",
      "Loaded 930 keywords for city domain\n",
      "可用的领域: ['video', 'music', 'city']\n",
      "随机选择了 500 条语句进行训练，原始数据集大小: 120098\n",
      "Train dataset size: 500\n",
      "Keywords directory: data/catslu\n",
      "Use keywords: True\n",
      "Using all available keywords for each domain\n",
      "Random sentences selection: enabled (training with 500 sentences)\n",
      "Domain randomization: enabled (randomly assigning domains to training samples)\n",
      "training on 2 GPUs\n",
      "[2025-06-02 20:56:41,821] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "  0%|                                                   | 0/500 [00:00<?, ?it/s]Domain randomization enabled. Randomly assigning domains from: ['video', 'music', 'city']Domain randomization enabled. Randomly assigning domains from: ['video', 'music', 'city']\n",
      "\n",
      "Domain randomization enabled. Randomly assigning domains from: ['video', 'music', 'city']\n",
      "Domain randomization enabled. Randomly assigning domains from: ['video', 'music', 'city']\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/v2129375/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "{'loss': 1.595, 'grad_norm': 19.625, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.02}\n",
      "{'loss': 0.8072, 'grad_norm': 8.1875, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.04}\n",
      "{'loss': 0.2841, 'grad_norm': 6.125, 'learning_rate': 2.4e-05, 'epoch': 0.06}   \n",
      "{'loss': 0.0646, 'grad_norm': 0.486328125, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0632, 'grad_norm': 20.875, 'learning_rate': 4e-05, 'epoch': 0.1}     \n",
      "{'loss': 0.1759, 'grad_norm': 0.03759765625, 'learning_rate': 3.9111111111111115e-05, 'epoch': 0.12}\n",
      "{'loss': 0.0117, 'grad_norm': 1.96875, 'learning_rate': 3.8222222222222226e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0589, 'grad_norm': 0.125, 'learning_rate': 3.733333333333334e-05, 'epoch': 0.16}\n",
      "{'loss': 0.1607, 'grad_norm': 0.365234375, 'learning_rate': 3.644444444444445e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0881, 'grad_norm': 4.4375, 'learning_rate': 3.555555555555555e-05, 'epoch': 0.2}\n",
      "{'loss': 0.4924, 'grad_norm': 42.0, 'learning_rate': 3.466666666666667e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0503, 'grad_norm': 9.75, 'learning_rate': 3.377777777777778e-05, 'epoch': 0.24}\n",
      "{'loss': 0.0739, 'grad_norm': 0.0068359375, 'learning_rate': 3.288888888888889e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0687, 'grad_norm': 0.0181884765625, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.28}\n",
      "{'loss': 0.0577, 'grad_norm': 11.875, 'learning_rate': 3.111111111111112e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0223, 'grad_norm': 0.019775390625, 'learning_rate': 3.0222222222222225e-05, 'epoch': 0.32}\n",
      "{'loss': 0.021, 'grad_norm': 6.59375, 'learning_rate': 2.9333333333333333e-05, 'epoch': 0.34}\n",
      "{'loss': 0.1032, 'grad_norm': 0.095703125, 'learning_rate': 2.8444444444444447e-05, 'epoch': 0.36}\n",
      "{'loss': 0.116, 'grad_norm': 0.2353515625, 'learning_rate': 2.755555555555556e-05, 'epoch': 0.38}\n",
      "{'loss': 0.1276, 'grad_norm': 5.3125, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.4}\n",
      "{'loss': 0.1042, 'grad_norm': 14.3125, 'learning_rate': 2.577777777777778e-05, 'epoch': 0.42}\n",
      "{'loss': 0.1132, 'grad_norm': 0.87109375, 'learning_rate': 2.4888888888888893e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0959, 'grad_norm': 9.5625, 'learning_rate': 2.4e-05, 'epoch': 0.46}  \n",
      "{'loss': 0.0742, 'grad_norm': 10.1875, 'learning_rate': 2.3111111111111112e-05, 'epoch': 0.48}\n",
      "{'loss': 0.1501, 'grad_norm': 0.0211181640625, 'learning_rate': 2.2222222222222227e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0417, 'grad_norm': 0.8984375, 'learning_rate': 2.1333333333333335e-05, 'epoch': 0.52}\n",
      "{'loss': 0.0386, 'grad_norm': 6.90625, 'learning_rate': 2.0444444444444446e-05, 'epoch': 0.54}\n",
      "{'loss': 0.0344, 'grad_norm': 5.28125, 'learning_rate': 1.9555555555555557e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0087, 'grad_norm': 0.00726318359375, 'learning_rate': 1.866666666666667e-05, 'epoch': 0.58}\n",
      "{'loss': 0.2323, 'grad_norm': 2.578125, 'learning_rate': 1.7777777777777777e-05, 'epoch': 0.6}\n",
      "{'loss': 0.3461, 'grad_norm': 29.625, 'learning_rate': 1.688888888888889e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0088, 'grad_norm': 0.020263671875, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.64}\n",
      "{'loss': 0.2852, 'grad_norm': 7.21875, 'learning_rate': 1.5111111111111112e-05, 'epoch': 0.66}\n",
      "{'loss': 0.0662, 'grad_norm': 0.007598876953125, 'learning_rate': 1.4222222222222224e-05, 'epoch': 0.68}\n",
      "{'loss': 0.0722, 'grad_norm': 9.0625, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.7}\n",
      "{'loss': 0.2024, 'grad_norm': 0.609375, 'learning_rate': 1.2444444444444446e-05, 'epoch': 0.72}\n",
      "{'loss': 0.0768, 'grad_norm': 0.050537109375, 'learning_rate': 1.1555555555555556e-05, 'epoch': 0.74}\n",
      "{'loss': 0.1601, 'grad_norm': 0.01318359375, 'learning_rate': 1.0666666666666667e-05, 'epoch': 0.76}\n",
      "{'loss': 0.2532, 'grad_norm': 0.2353515625, 'learning_rate': 9.777777777777779e-06, 'epoch': 0.78}\n",
      "{'loss': 0.0023, 'grad_norm': 0.0033721923828125, 'learning_rate': 8.888888888888888e-06, 'epoch': 0.8}\n",
      "{'loss': 0.0012, 'grad_norm': 0.1533203125, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.82}\n",
      "{'loss': 0.041, 'grad_norm': 0.466796875, 'learning_rate': 7.111111111111112e-06, 'epoch': 0.84}\n",
      "{'loss': 0.0647, 'grad_norm': 0.0238037109375, 'learning_rate': 6.222222222222223e-06, 'epoch': 0.86}\n",
      "{'loss': 0.0415, 'grad_norm': 0.03955078125, 'learning_rate': 5.333333333333334e-06, 'epoch': 0.88}\n",
      "{'loss': 0.0121, 'grad_norm': 0.09765625, 'learning_rate': 4.444444444444444e-06, 'epoch': 0.9}\n",
      "{'loss': 0.5221, 'grad_norm': 0.03125, 'learning_rate': 3.555555555555556e-06, 'epoch': 0.92}\n",
      "{'loss': 0.0739, 'grad_norm': 0.5234375, 'learning_rate': 2.666666666666667e-06, 'epoch': 0.94}\n",
      "{'loss': 0.1124, 'grad_norm': 0.06396484375, 'learning_rate': 1.777777777777778e-06, 'epoch': 0.96}\n",
      "{'loss': 0.0915, 'grad_norm': 0.0322265625, 'learning_rate': 8.88888888888889e-07, 'epoch': 0.98}\n",
      "{'loss': 0.1825, 'grad_norm': 6.875, 'learning_rate': 0.0, 'epoch': 1.0}        \n",
      "{'train_runtime': 618.1091, 'train_samples_per_second': 0.809, 'train_steps_per_second': 0.809, 'train_loss': 0.15904424254782498, 'epoch': 1.0}\n",
      "100%|█████████████████████████████████████████| 500/500 [10:18<00:00,  1.24s/it]\n",
      "Training completed successfully!\n",
      "第 2/3 次微调任务完成\n",
      "\n",
      "使用关键词: True\n",
      "使用所有可用的关键词\n",
      "使用GPU: [0, 1]\n",
      "/home/v2129375/miniconda3/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:590: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "正在加载模型到{'model.embed_tokens': 0, 'model.embed_dropout': 0, 'model.embed_tokens_extend': 0, 'lm_head': 0, 'model.layers.0': 1, 'model.layers.1': 1, 'model.layers.2': 1, 'model.layers.3': 1, 'model.layers.4': 1, 'model.layers.5': 1, 'model.layers.6': 1, 'model.layers.7': 1, 'model.layers.8': 1, 'model.layers.9': 1, 'model.layers.10': 1, 'model.layers.11': 1, 'model.layers.12': 1, 'model.layers.13': 1, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 1, 'model.layers.17': 1, 'model.layers.18': 1, 'model.layers.19': 1, 'model.layers.20': 1, 'model.layers.21': 1, 'model.layers.22': 1, 'model.layers.23': 1, 'model.layers.24': 1, 'model.layers.25': 1, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1}...\n",
      "/home/v2129375/miniconda3/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:590: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n",
      "/home/v2129375/.cache/huggingface/modules/transformers_modules/500aishell1p2keywords/speech_conformer_encoder.py:2774: FutureWarning: Please specify CheckpointImpl.NO_REENTRANT as CheckpointImpl.REENTRANT will soon be removed as the default and eventually deprecated.\n",
      "  lambda i: encoder_checkpoint_wrapper(\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "模型分布情况:\n",
      "  model.embed_tokens: 0\n",
      "  model.embed_dropout: 0\n",
      "  model.embed_tokens_extend: 0\n",
      "  lm_head: 0\n",
      "  model.layers.0: 1\n",
      "  model.layers.1: 1\n",
      "  model.layers.2: 1\n",
      "  model.layers.3: 1\n",
      "  model.layers.4: 1\n",
      "  model.layers.5: 1\n",
      "  model.layers.6: 1\n",
      "  model.layers.7: 1\n",
      "  model.layers.8: 1\n",
      "  model.layers.9: 1\n",
      "  model.layers.10: 1\n",
      "  model.layers.11: 1\n",
      "  model.layers.12: 1\n",
      "  model.layers.13: 1\n",
      "  model.layers.14: 1\n",
      "  model.layers.15: 1\n",
      "  model.layers.16: 1\n",
      "  model.layers.17: 1\n",
      "  model.layers.18: 1\n",
      "  model.layers.19: 1\n",
      "  model.layers.20: 1\n",
      "  model.layers.21: 1\n",
      "  model.layers.22: 1\n",
      "  model.layers.23: 1\n",
      "  model.layers.24: 1\n",
      "  model.layers.25: 1\n",
      "  model.layers.26: 1\n",
      "  model.layers.27: 1\n",
      "  model.layers.28: 1\n",
      "  model.layers.29: 1\n",
      "  model.layers.30: 1\n",
      "  model.layers.31: 1\n",
      "  model.norm: 1\n",
      "Loaded 555 keywords for video domain\n",
      "Loaded 390 keywords for music domain\n",
      "Loaded 930 keywords for city domain\n",
      "处理音频:   0%|                                         | 0/378 [00:00<?, ?it/s]/home/v2129375/asr_biasing/asr/phi4_keywords.py:212: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "/home/v2129375/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "处理音频: 100%|███████████████████████████████| 378/378 [04:55<00:00,  1.28it/s]\n",
      "\n",
      "开始评估ASR结果...\n",
      "\n",
      "错误识别的样本:\n",
      "原始文本: 红日\n",
      "识别结果: 同日\n",
      "关键词: 红日\n",
      "---\n",
      "原始文本: 十万个为什么\n",
      "识别结果: 问个为什么\n",
      "关键词: 十万个为什么\n",
      "---\n",
      "原始文本: 我想看楚乔传\n",
      "识别结果: 我想看处巧传\n",
      "关键词: 楚乔传\n",
      "---\n",
      "原始文本: 猪小妹\n",
      "识别结果: 朱小妹\n",
      "关键词: 猪小妹\n",
      "---\n",
      "原始文本: 我想看汪汪队\n",
      "识别结果: 我想看旺旺队\n",
      "关键词: 汪汪队\n",
      "---\n",
      "原始文本: 播放艾利之书\n",
      "识别结果: 播放安利之书\n",
      "关键词: 艾利之书\n",
      "---\n",
      "原始文本: 我要看汪汪队立大功\n",
      "识别结果: 我要看旺旺队立大功\n",
      "关键词: 汪汪队立大功\n",
      "---\n",
      "原始文本: 播放猩球崛起三\n",
      "识别结果: 播放星球决策三\n",
      "关键词: 猩球崛起三\n",
      "---\n",
      "原始文本: 世上只有妈妈好\n",
      "识别结果: 四川只有妈妈好\n",
      "关键词: 世上只有妈妈好\n",
      "---\n",
      "原始文本: 播放艾利之书\n",
      "识别结果: 播放爱丽丝之书\n",
      "关键词: 艾利之书\n",
      "---\n",
      "原始文本: 小飞侠\n",
      "识别结果: 小飞象玩这个那个飞车玩不好\n",
      "关键词: 小飞侠\n",
      "---\n",
      "原始文本: 放白雪公主\n",
      "识别结果: 放白鞋公主\n",
      "关键词: 白雪公主\n",
      "---\n",
      "原始文本: 放小白兔白又白\n",
      "识别结果: 唱一下白兔白白白\n",
      "关键词: 小白兔白又白\n",
      "---\n",
      "原始文本: 钱塘老娘舅\n",
      "识别结果: 前谈老娘舅\n",
      "关键词: 钱塘老娘舅\n",
      "---\n",
      "原始文本: 播放超级会飞侠第三季\n",
      "识别结果: 播放超级灰飞侠第三季\n",
      "关键词: 超级会飞侠\n",
      "---\n",
      "原始文本: 播放读书郎\n",
      "识别结果: 播放读书狼\n",
      "关键词: 读书郎\n",
      "---\n",
      "原始文本: 播放巧虎来啦\n",
      "识别结果: 播放巧虎来了\n",
      "关键词: 巧虎来啦\n",
      "---\n",
      "原始文本: 请放一首张明敏的我的中国心\n",
      "识别结果: 请放一首张云林的我的中国心\n",
      "关键词: 张明敏\n",
      "---\n",
      "原始文本: 唱小蓓蕾儿儿歌\n",
      "识别结果: 唱小贝勒儿歌\n",
      "关键词: 小蓓蕾\n",
      "---\n",
      "原始文本: 梦然唱的没有你陪伴真的好孤单\n",
      "识别结果: 梦来唱的没有你陪伴真的好孤单你快要\n",
      "关键词: 梦然\n",
      "---\n",
      "原始文本: 云菲菲的都市情缘\n",
      "识别结果: 云飞飞的都市情缘\n",
      "关键词: 云菲菲\n",
      "---\n",
      "原始文本: 祁隆的歌爰的世界只有你\n",
      "识别结果: 启龙的歌爱的世界只有你\n",
      "关键词: 祁隆\n",
      "---\n",
      "原始文本: 张宇的一言难尽\n",
      "识别结果: 张雨的一言难尽\n",
      "关键词: 张宇\n",
      "---\n",
      "原始文本: 樊竹青的歌曲\n",
      "识别结果: 樊足轻的歌曲\n",
      "关键词: 樊竹青\n",
      "---\n",
      "原始文本: 唱一首王蓉的小鸡小鸡\n",
      "识别结果: 唱一首八零的小鸡小鸡\n",
      "关键词: 王蓉\n",
      "---\n",
      "原始文本: 潘玮柏的\n",
      "识别结果: 听潘伟伯的\n",
      "关键词: 潘玮柏\n",
      "---\n",
      "原始文本: 张宇的一言难尽\n",
      "识别结果: 张雨的一言难尽\n",
      "关键词: 张宇\n",
      "---\n",
      "原始文本: 黄蓉小鸡小鸡\n",
      "识别结果: 黄龙小鸡小鸡\n",
      "关键词: 黄蓉\n",
      "---\n",
      "原始文本: 汪苏泷那个男孩\n",
      "识别结果: 公主龙那个男孩\n",
      "关键词: 汪苏泷\n",
      "---\n",
      "原始文本: 来一首王绎龙的摇摆哥\n",
      "识别结果: 来一首王毅龙的摇摆歌\n",
      "关键词: 王绎龙\n",
      "---\n",
      "原始文本: 唱一首伍佰的歌\n",
      "识别结果: 唱一首吴佰的歌\n",
      "关键词: 伍佰\n",
      "---\n",
      "原始文本: 小乐明天杭州天气怎么样\n",
      "识别结果: 小乐明天汉江的天气怎么样\n",
      "关键词: 杭州\n",
      "---\n",
      "原始文本: 鄂州\n",
      "识别结果: 我们走了\n",
      "关键词: 鄂州\n",
      "---\n",
      "原始文本: 嗯现在深深圳天气怎么样\n",
      "识别结果: 韩红\n",
      "关键词: 深深圳\n",
      "---\n",
      "原始文本: 北京后天的天气怎么样\n",
      "识别结果: 三十三\n",
      "关键词: 北京\n",
      "---\n",
      "原始文本: 我要看兰州天气\n",
      "识别结果: 我要看南通的天气\n",
      "关键词: 兰州\n",
      "---\n",
      "原始文本: 绥化\n",
      "识别结果: 谁话\n",
      "关键词: 绥化\n",
      "---\n",
      "原始文本: 长沙后天的天气\n",
      "识别结果: 查查后天的天气\n",
      "关键词: 长沙\n",
      "---\n",
      "原始文本: 亳州的天气怎么样\n",
      "识别结果: 灰姑娘幻影忍者三毛流浪记赌霸恭喜发财唱歌上灯台偷下不来小白兔白又白小毛驴小白兔白又白\n",
      "关键词: 亳州\n",
      "---\n",
      "\n",
      "总体结果:\n",
      "CER: 0.1061\n",
      "Keyword WER: 0.1032\n",
      "\n",
      "各类别结果:\n",
      "\n",
      "类别: video\n",
      "样本数: 157\n",
      "CER: 0.1044\n",
      "Keyword WER: 0.1083\n",
      "\n",
      "类别: music\n",
      "样本数: 101\n",
      "CER: 0.0730\n",
      "Keyword WER: 0.1386\n",
      "\n",
      "类别: city\n",
      "样本数: 120\n",
      "CER: 0.1362\n",
      "Keyword WER: 0.0667\n",
      "\n",
      "结果已保存到: asr/exp/new.json\n",
      "第 2/3 次评估完成\n",
      "\n",
      "开始执行第 3/3 次微调任务\n",
      "参数: num_sentences=1500, output_dir=asr/model/1500aishell1p2keywords\n",
      "执行命令: python /home/v2129375/asr_biasing/asr/aishell_finetune/finetune_aishell_keywords.py --num_sentences 1500 --output_dir asr/model/1500aishell1p2keywords\n",
      "/home/v2129375/miniconda3/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:590: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "使用GPU: [0, 1]\n",
      "/home/v2129375/.cache/huggingface/modules/transformers_modules/microsoft/Phi-4-multimodal-instruct/33e62acdd07cd7d6635badd529aa0a3467bb9c6a/speech_conformer_encoder.py:2774: FutureWarning: Please specify CheckpointImpl.NO_REENTRANT as CheckpointImpl.REENTRANT will soon be removed as the default and eventually deprecated.\n",
      "  lambda i: encoder_checkpoint_wrapper(\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "警告: 数据集中没有发现'source'列。在RANDOMIZE_DOMAIN=True时将随机分配领域。\n",
      "Loaded 555 keywords for video domain\n",
      "Loaded 390 keywords for music domain\n",
      "Loaded 930 keywords for city domain\n",
      "可用的领域: ['video', 'music', 'city']\n",
      "随机选择了 1500 条语句进行训练，原始数据集大小: 120098\n",
      "Train dataset size: 1500\n",
      "Keywords directory: data/catslu\n",
      "Use keywords: True\n",
      "Using all available keywords for each domain\n",
      "Random sentences selection: enabled (training with 1500 sentences)\n",
      "Domain randomization: enabled (randomly assigning domains to training samples)\n",
      "training on 2 GPUs\n",
      "[2025-06-02 21:12:24,031] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "  0%|                                                  | 0/1500 [00:00<?, ?it/s]Domain randomization enabled. Randomly assigning domains from: ['video', 'music', 'city']\n",
      "Domain randomization enabled. Randomly assigning domains from: ['video', 'music', 'city']\n",
      "Domain randomization enabled. Randomly assigning domains from: ['video', 'music', 'city']\n",
      "Domain randomization enabled. Randomly assigning domains from: ['video', 'music', 'city']\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/v2129375/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "{'loss': 1.8914, 'grad_norm': 38.5, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.01}\n",
      "{'loss': 0.9478, 'grad_norm': 22.375, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.01}\n",
      "{'loss': 0.321, 'grad_norm': 1.1640625, 'learning_rate': 2.4e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1202, 'grad_norm': 3.046875, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0768, 'grad_norm': 1.5234375, 'learning_rate': 4e-05, 'epoch': 0.03} \n",
      "{'loss': 0.1354, 'grad_norm': 19.875, 'learning_rate': 3.972413793103449e-05, 'epoch': 0.04}\n",
      "{'loss': 0.1079, 'grad_norm': 0.1220703125, 'learning_rate': 3.9448275862068966e-05, 'epoch': 0.05}\n",
      "{'loss': 0.1035, 'grad_norm': 20.125, 'learning_rate': 3.917241379310345e-05, 'epoch': 0.05}\n",
      "{'loss': 0.039, 'grad_norm': 0.040771484375, 'learning_rate': 3.8896551724137935e-05, 'epoch': 0.06}\n",
      "{'loss': 0.1911, 'grad_norm': 17.25, 'learning_rate': 3.862068965517242e-05, 'epoch': 0.07}\n",
      "{'loss': 0.1281, 'grad_norm': 0.037353515625, 'learning_rate': 3.83448275862069e-05, 'epoch': 0.07}\n",
      "{'loss': 0.1045, 'grad_norm': 0.0301513671875, 'learning_rate': 3.806896551724138e-05, 'epoch': 0.08}\n",
      "{'loss': 0.048, 'grad_norm': 0.12255859375, 'learning_rate': 3.779310344827587e-05, 'epoch': 0.09}\n",
      "{'loss': 0.225, 'grad_norm': 0.1240234375, 'learning_rate': 3.7517241379310345e-05, 'epoch': 0.09}\n",
      "{'loss': 0.2379, 'grad_norm': 0.0859375, 'learning_rate': 3.724137931034483e-05, 'epoch': 0.1}\n",
      "{'loss': 0.0093, 'grad_norm': 2.078125, 'learning_rate': 3.6965517241379315e-05, 'epoch': 0.11}\n",
      "{'loss': 0.2958, 'grad_norm': 9.9375, 'learning_rate': 3.668965517241379e-05, 'epoch': 0.11}\n",
      "{'loss': 0.3862, 'grad_norm': 0.078125, 'learning_rate': 3.641379310344828e-05, 'epoch': 0.12}\n",
      "{'loss': 0.1088, 'grad_norm': 2.828125, 'learning_rate': 3.613793103448276e-05, 'epoch': 0.13}\n",
      "{'loss': 0.0026, 'grad_norm': 0.0078125, 'learning_rate': 3.586206896551725e-05, 'epoch': 0.13}\n",
      "{'loss': 0.0716, 'grad_norm': 3.8125, 'learning_rate': 3.5586206896551725e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0522, 'grad_norm': 2.109375, 'learning_rate': 3.531034482758621e-05, 'epoch': 0.15}\n",
      "{'loss': 0.2376, 'grad_norm': 12.0625, 'learning_rate': 3.5034482758620694e-05, 'epoch': 0.15}\n",
      "{'loss': 0.2541, 'grad_norm': 0.00970458984375, 'learning_rate': 3.475862068965517e-05, 'epoch': 0.16}\n",
      "{'loss': 0.0542, 'grad_norm': 0.1416015625, 'learning_rate': 3.4482758620689657e-05, 'epoch': 0.17}\n",
      "{'loss': 0.1311, 'grad_norm': 28.625, 'learning_rate': 3.420689655172414e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0904, 'grad_norm': 8.125, 'learning_rate': 3.3931034482758626e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0037, 'grad_norm': 0.040283203125, 'learning_rate': 3.3655172413793104e-05, 'epoch': 0.19}\n",
      "{'loss': 0.1655, 'grad_norm': 0.03076171875, 'learning_rate': 3.337931034482759e-05, 'epoch': 0.19}\n",
      "{'loss': 0.297, 'grad_norm': 3.078125, 'learning_rate': 3.310344827586207e-05, 'epoch': 0.2}\n",
      "{'loss': 0.0837, 'grad_norm': 0.08984375, 'learning_rate': 3.282758620689655e-05, 'epoch': 0.21}\n",
      "{'loss': 0.0095, 'grad_norm': 0.427734375, 'learning_rate': 3.2551724137931036e-05, 'epoch': 0.21}\n",
      "{'loss': 0.0234, 'grad_norm': 0.007293701171875, 'learning_rate': 3.227586206896552e-05, 'epoch': 0.22}\n",
      "{'loss': 0.2082, 'grad_norm': 1.25, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.23}\n",
      "{'loss': 0.1331, 'grad_norm': 0.08935546875, 'learning_rate': 3.172413793103448e-05, 'epoch': 0.23}\n",
      "{'loss': 0.0483, 'grad_norm': 0.0299072265625, 'learning_rate': 3.144827586206897e-05, 'epoch': 0.24}\n",
      "{'loss': 0.2518, 'grad_norm': 2.5, 'learning_rate': 3.117241379310345e-05, 'epoch': 0.25}\n",
      "{'loss': 0.0692, 'grad_norm': 0.0024261474609375, 'learning_rate': 3.089655172413793e-05, 'epoch': 0.25}\n",
      "{'loss': 0.1246, 'grad_norm': 0.2373046875, 'learning_rate': 3.0620689655172415e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0391, 'grad_norm': 9.8125, 'learning_rate': 3.0344827586206897e-05, 'epoch': 0.27}\n",
      "{'loss': 0.1902, 'grad_norm': 0.022705078125, 'learning_rate': 3.006896551724138e-05, 'epoch': 0.27}\n",
      "{'loss': 0.1073, 'grad_norm': 2.859375, 'learning_rate': 2.9793103448275866e-05, 'epoch': 0.28}\n",
      "{'loss': 0.0619, 'grad_norm': 0.130859375, 'learning_rate': 2.9517241379310347e-05, 'epoch': 0.29}\n",
      "{'loss': 0.0517, 'grad_norm': 0.059814453125, 'learning_rate': 2.9241379310344832e-05, 'epoch': 0.29}\n",
      "{'loss': 0.3865, 'grad_norm': 0.048583984375, 'learning_rate': 2.8965517241379313e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0204, 'grad_norm': 0.294921875, 'learning_rate': 2.8689655172413795e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0497, 'grad_norm': 17.625, 'learning_rate': 2.8413793103448276e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0725, 'grad_norm': 0.031494140625, 'learning_rate': 2.813793103448276e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0392, 'grad_norm': 0.0947265625, 'learning_rate': 2.7862068965517242e-05, 'epoch': 0.33}\n",
      "{'loss': 0.2327, 'grad_norm': 0.016357421875, 'learning_rate': 2.7586206896551727e-05, 'epoch': 0.33}\n",
      "{'loss': 0.0595, 'grad_norm': 0.00860595703125, 'learning_rate': 2.731034482758621e-05, 'epoch': 0.34}\n",
      "{'loss': 0.0612, 'grad_norm': 3.5, 'learning_rate': 2.7034482758620693e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0779, 'grad_norm': 0.0164794921875, 'learning_rate': 2.6758620689655174e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0218, 'grad_norm': 0.0211181640625, 'learning_rate': 2.648275862068966e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0256, 'grad_norm': 8.75, 'learning_rate': 2.620689655172414e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0308, 'grad_norm': 7.65625, 'learning_rate': 2.593103448275862e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0824, 'grad_norm': 9.625, 'learning_rate': 2.5655172413793103e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0159, 'grad_norm': 6.6875, 'learning_rate': 2.537931034482759e-05, 'epoch': 0.39}\n",
      "{'loss': 0.0387, 'grad_norm': 9.0, 'learning_rate': 2.5103448275862072e-05, 'epoch': 0.39}\n",
      "{'loss': 0.0336, 'grad_norm': 0.00823974609375, 'learning_rate': 2.4827586206896553e-05, 'epoch': 0.4}\n",
      "{'loss': 0.1319, 'grad_norm': 1.3125, 'learning_rate': 2.4551724137931038e-05, 'epoch': 0.41}\n",
      "{'loss': 0.2219, 'grad_norm': 0.05078125, 'learning_rate': 2.427586206896552e-05, 'epoch': 0.41}\n",
      "{'loss': 0.0692, 'grad_norm': 5.03125, 'learning_rate': 2.4e-05, 'epoch': 0.42} \n",
      "{'loss': 0.2675, 'grad_norm': 1.8359375, 'learning_rate': 2.3724137931034482e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0489, 'grad_norm': 0.0299072265625, 'learning_rate': 2.3448275862068967e-05, 'epoch': 0.43}\n",
      "{'loss': 0.2065, 'grad_norm': 0.076171875, 'learning_rate': 2.317241379310345e-05, 'epoch': 0.44}\n",
      "{'loss': 0.1753, 'grad_norm': 0.77734375, 'learning_rate': 2.2896551724137933e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0171, 'grad_norm': 0.035888671875, 'learning_rate': 2.2620689655172417e-05, 'epoch': 0.45}\n",
      "{'loss': 0.2693, 'grad_norm': 0.05810546875, 'learning_rate': 2.23448275862069e-05, 'epoch': 0.46}\n",
      "{'loss': 0.189, 'grad_norm': 0.0947265625, 'learning_rate': 2.206896551724138e-05, 'epoch': 0.47}\n",
      "{'loss': 0.1629, 'grad_norm': 6.25, 'learning_rate': 2.1793103448275865e-05, 'epoch': 0.47}\n",
      "{'loss': 0.1944, 'grad_norm': 0.1640625, 'learning_rate': 2.1517241379310346e-05, 'epoch': 0.48}\n",
      "{'loss': 0.1933, 'grad_norm': 3.59375, 'learning_rate': 2.1241379310344827e-05, 'epoch': 0.49}\n",
      "{'loss': 0.1438, 'grad_norm': 9.875, 'learning_rate': 2.0965517241379315e-05, 'epoch': 0.49}\n",
      "{'loss': 0.0195, 'grad_norm': 0.6796875, 'learning_rate': 2.0689655172413797e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0802, 'grad_norm': 7.34375, 'learning_rate': 2.0413793103448278e-05, 'epoch': 0.51}\n",
      "{'loss': 0.0039, 'grad_norm': 0.007415771484375, 'learning_rate': 2.013793103448276e-05, 'epoch': 0.51}\n",
      "{'loss': 0.1795, 'grad_norm': 1.7421875, 'learning_rate': 1.9862068965517244e-05, 'epoch': 0.52}\n",
      "{'loss': 0.0326, 'grad_norm': 0.002166748046875, 'learning_rate': 1.9586206896551725e-05, 'epoch': 0.53}\n",
      "{'loss': 0.035, 'grad_norm': 0.01495361328125, 'learning_rate': 1.931034482758621e-05, 'epoch': 0.53}\n",
      "{'loss': 0.3043, 'grad_norm': 7.4375, 'learning_rate': 1.903448275862069e-05, 'epoch': 0.54}\n",
      "{'loss': 0.3592, 'grad_norm': 25.125, 'learning_rate': 1.8758620689655173e-05, 'epoch': 0.55}\n",
      "{'loss': 0.0178, 'grad_norm': 1.890625, 'learning_rate': 1.8482758620689657e-05, 'epoch': 0.55}\n",
      "{'loss': 0.0581, 'grad_norm': 0.00830078125, 'learning_rate': 1.820689655172414e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0769, 'grad_norm': 12.0, 'learning_rate': 1.7931034482758623e-05, 'epoch': 0.57}\n",
      "{'loss': 0.1826, 'grad_norm': 9.25, 'learning_rate': 1.7655172413793105e-05, 'epoch': 0.57}\n",
      "{'loss': 0.0448, 'grad_norm': 0.0235595703125, 'learning_rate': 1.7379310344827586e-05, 'epoch': 0.58}\n",
      "{'loss': 0.0978, 'grad_norm': 0.0014190673828125, 'learning_rate': 1.710344827586207e-05, 'epoch': 0.59}\n",
      "{'loss': 0.0819, 'grad_norm': 9.8125, 'learning_rate': 1.6827586206896552e-05, 'epoch': 0.59}\n",
      "{'loss': 0.0274, 'grad_norm': 0.1298828125, 'learning_rate': 1.6551724137931037e-05, 'epoch': 0.6}\n",
      "{'loss': 0.0347, 'grad_norm': 0.0238037109375, 'learning_rate': 1.6275862068965518e-05, 'epoch': 0.61}\n",
      "{'loss': 0.0699, 'grad_norm': 0.005950927734375, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.61}\n",
      "{'loss': 0.057, 'grad_norm': 4.9375, 'learning_rate': 1.5724137931034484e-05, 'epoch': 0.62}\n",
      "{'loss': 0.1107, 'grad_norm': 0.0126953125, 'learning_rate': 1.5448275862068965e-05, 'epoch': 0.63}\n",
      "{'loss': 0.0804, 'grad_norm': 1.234375, 'learning_rate': 1.5172413793103448e-05, 'epoch': 0.63}\n",
      "{'loss': 0.2355, 'grad_norm': 7.6875, 'learning_rate': 1.4896551724137933e-05, 'epoch': 0.64}\n",
      "{'loss': 0.1963, 'grad_norm': 12.25, 'learning_rate': 1.4620689655172416e-05, 'epoch': 0.65}\n",
      "{'loss': 0.0406, 'grad_norm': 23.875, 'learning_rate': 1.4344827586206897e-05, 'epoch': 0.65}\n",
      "{'loss': 0.2247, 'grad_norm': 0.0196533203125, 'learning_rate': 1.406896551724138e-05, 'epoch': 0.66}\n",
      "{'loss': 0.0017, 'grad_norm': 0.0009613037109375, 'learning_rate': 1.3793103448275863e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0802, 'grad_norm': 8.4375, 'learning_rate': 1.3517241379310346e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0698, 'grad_norm': 12.8125, 'learning_rate': 1.324137931034483e-05, 'epoch': 0.68}\n",
      "{'loss': 0.1612, 'grad_norm': 0.1806640625, 'learning_rate': 1.296551724137931e-05, 'epoch': 0.69}\n",
      "{'loss': 0.0862, 'grad_norm': 0.72265625, 'learning_rate': 1.2689655172413795e-05, 'epoch': 0.69}\n",
      "{'loss': 0.0338, 'grad_norm': 0.462890625, 'learning_rate': 1.2413793103448277e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0239, 'grad_norm': 0.875, 'learning_rate': 1.213793103448276e-05, 'epoch': 0.71}\n",
      "{'loss': 0.0305, 'grad_norm': 0.197265625, 'learning_rate': 1.1862068965517241e-05, 'epoch': 0.71}\n",
      "{'loss': 0.0838, 'grad_norm': 0.08154296875, 'learning_rate': 1.1586206896551726e-05, 'epoch': 0.72}\n",
      "{'loss': 0.0567, 'grad_norm': 0.5234375, 'learning_rate': 1.1310344827586209e-05, 'epoch': 0.73}\n",
      "{'loss': 0.0102, 'grad_norm': 0.1357421875, 'learning_rate': 1.103448275862069e-05, 'epoch': 0.73}\n",
      "{'loss': 0.0659, 'grad_norm': 0.146484375, 'learning_rate': 1.0758620689655173e-05, 'epoch': 0.74}\n",
      "{'loss': 0.0737, 'grad_norm': 7.46875, 'learning_rate': 1.0482758620689658e-05, 'epoch': 0.75}\n",
      "{'loss': 0.0509, 'grad_norm': 0.00811767578125, 'learning_rate': 1.0206896551724139e-05, 'epoch': 0.75}\n",
      "{'loss': 0.3037, 'grad_norm': 13.625, 'learning_rate': 9.931034482758622e-06, 'epoch': 0.76}\n",
      "{'loss': 0.1499, 'grad_norm': 1.6953125, 'learning_rate': 9.655172413793105e-06, 'epoch': 0.77}\n",
      "{'loss': 0.0133, 'grad_norm': 0.0021514892578125, 'learning_rate': 9.379310344827586e-06, 'epoch': 0.77}\n",
      "{'loss': 0.178, 'grad_norm': 12.5, 'learning_rate': 9.10344827586207e-06, 'epoch': 0.78}\n",
      "{'loss': 0.0905, 'grad_norm': 4.0625, 'learning_rate': 8.827586206896552e-06, 'epoch': 0.79}\n",
      "{'loss': 0.0749, 'grad_norm': 0.875, 'learning_rate': 8.551724137931035e-06, 'epoch': 0.79}\n",
      "{'loss': 0.0072, 'grad_norm': 0.0634765625, 'learning_rate': 8.275862068965518e-06, 'epoch': 0.8}\n",
      "{'loss': 0.0154, 'grad_norm': 0.036376953125, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.81}\n",
      "{'loss': 0.103, 'grad_norm': 0.0091552734375, 'learning_rate': 7.724137931034483e-06, 'epoch': 0.81}\n",
      "{'loss': 0.0754, 'grad_norm': 0.76171875, 'learning_rate': 7.4482758620689665e-06, 'epoch': 0.82}\n",
      "{'loss': 0.205, 'grad_norm': 0.30078125, 'learning_rate': 7.172413793103449e-06, 'epoch': 0.83}\n",
      "{'loss': 0.0114, 'grad_norm': 0.3671875, 'learning_rate': 6.896551724137932e-06, 'epoch': 0.83}\n",
      "{'loss': 0.1492, 'grad_norm': 14.75, 'learning_rate': 6.620689655172415e-06, 'epoch': 0.84}\n",
      "{'loss': 0.003, 'grad_norm': 0.046142578125, 'learning_rate': 6.344827586206898e-06, 'epoch': 0.85}\n",
      "{'loss': 0.1308, 'grad_norm': 8.625, 'learning_rate': 6.06896551724138e-06, 'epoch': 0.85}\n",
      "{'loss': 0.0484, 'grad_norm': 0.0030059814453125, 'learning_rate': 5.793103448275863e-06, 'epoch': 0.86}\n",
      "{'loss': 0.1928, 'grad_norm': 18.625, 'learning_rate': 5.517241379310345e-06, 'epoch': 0.87}\n",
      "{'loss': 0.1968, 'grad_norm': 0.02734375, 'learning_rate': 5.241379310344829e-06, 'epoch': 0.87}\n",
      "{'loss': 0.1215, 'grad_norm': 18.625, 'learning_rate': 4.965517241379311e-06, 'epoch': 0.88}\n",
      "{'loss': 0.0902, 'grad_norm': 0.89453125, 'learning_rate': 4.689655172413793e-06, 'epoch': 0.89}\n",
      "{'loss': 0.1327, 'grad_norm': 8.4375, 'learning_rate': 4.413793103448276e-06, 'epoch': 0.89}\n",
      "{'loss': 0.0004, 'grad_norm': 0.005859375, 'learning_rate': 4.137931034482759e-06, 'epoch': 0.9}\n",
      "{'loss': 0.0792, 'grad_norm': 0.004547119140625, 'learning_rate': 3.862068965517241e-06, 'epoch': 0.91}\n",
      "{'loss': 0.0064, 'grad_norm': 0.046875, 'learning_rate': 3.5862068965517243e-06, 'epoch': 0.91}\n",
      "{'loss': 0.0058, 'grad_norm': 0.2431640625, 'learning_rate': 3.3103448275862073e-06, 'epoch': 0.92}\n",
      "{'loss': 0.1759, 'grad_norm': 0.001953125, 'learning_rate': 3.03448275862069e-06, 'epoch': 0.93}\n",
      "{'loss': 0.0419, 'grad_norm': 0.02783203125, 'learning_rate': 2.7586206896551725e-06, 'epoch': 0.93}\n",
      "{'loss': 0.2375, 'grad_norm': 0.00946044921875, 'learning_rate': 2.4827586206896555e-06, 'epoch': 0.94}\n",
      "{'loss': 0.1334, 'grad_norm': 0.53515625, 'learning_rate': 2.206896551724138e-06, 'epoch': 0.95}\n",
      "{'loss': 0.2383, 'grad_norm': 1.171875, 'learning_rate': 1.9310344827586207e-06, 'epoch': 0.95}\n",
      "{'loss': 0.0445, 'grad_norm': 3.484375, 'learning_rate': 1.6551724137931037e-06, 'epoch': 0.96}\n",
      "{'loss': 0.0491, 'grad_norm': 0.02880859375, 'learning_rate': 1.3793103448275862e-06, 'epoch': 0.97}\n",
      "{'loss': 0.1248, 'grad_norm': 7.90625, 'learning_rate': 1.103448275862069e-06, 'epoch': 0.97}\n",
      "{'loss': 0.1776, 'grad_norm': 0.0037689208984375, 'learning_rate': 8.275862068965518e-07, 'epoch': 0.98}\n",
      "{'loss': 0.0344, 'grad_norm': 4.875, 'learning_rate': 5.517241379310345e-07, 'epoch': 0.99}\n",
      "{'loss': 0.2857, 'grad_norm': 6.34375, 'learning_rate': 2.7586206896551726e-07, 'epoch': 0.99}\n",
      "{'loss': 0.4321, 'grad_norm': 0.0223388671875, 'learning_rate': 0.0, 'epoch': 1.0}\n",
      "{'train_runtime': 1853.1107, 'train_samples_per_second': 0.809, 'train_steps_per_second': 0.809, 'train_loss': 0.130792548730659, 'epoch': 1.0}\n",
      "100%|███████████████████████████████████████| 1500/1500 [30:53<00:00,  1.24s/it]\n",
      "Training completed successfully!\n",
      "第 3/3 次微调任务完成\n",
      "\n",
      "使用关键词: True\n",
      "使用所有可用的关键词\n",
      "使用GPU: [0, 1]\n",
      "/home/v2129375/miniconda3/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:590: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "正在加载模型到{'model.embed_tokens': 0, 'model.embed_dropout': 0, 'model.embed_tokens_extend': 0, 'lm_head': 0, 'model.layers.0': 1, 'model.layers.1': 1, 'model.layers.2': 1, 'model.layers.3': 1, 'model.layers.4': 1, 'model.layers.5': 1, 'model.layers.6': 1, 'model.layers.7': 1, 'model.layers.8': 1, 'model.layers.9': 1, 'model.layers.10': 1, 'model.layers.11': 1, 'model.layers.12': 1, 'model.layers.13': 1, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 1, 'model.layers.17': 1, 'model.layers.18': 1, 'model.layers.19': 1, 'model.layers.20': 1, 'model.layers.21': 1, 'model.layers.22': 1, 'model.layers.23': 1, 'model.layers.24': 1, 'model.layers.25': 1, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1}...\n",
      "/home/v2129375/miniconda3/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:590: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n",
      "/home/v2129375/.cache/huggingface/modules/transformers_modules/1500aishell1p2keywords/speech_conformer_encoder.py:2774: FutureWarning: Please specify CheckpointImpl.NO_REENTRANT as CheckpointImpl.REENTRANT will soon be removed as the default and eventually deprecated.\n",
      "  lambda i: encoder_checkpoint_wrapper(\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:01<00:00,  1.69it/s]\n",
      "模型分布情况:\n",
      "  model.embed_tokens: 0\n",
      "  model.embed_dropout: 0\n",
      "  model.embed_tokens_extend: 0\n",
      "  lm_head: 0\n",
      "  model.layers.0: 1\n",
      "  model.layers.1: 1\n",
      "  model.layers.2: 1\n",
      "  model.layers.3: 1\n",
      "  model.layers.4: 1\n",
      "  model.layers.5: 1\n",
      "  model.layers.6: 1\n",
      "  model.layers.7: 1\n",
      "  model.layers.8: 1\n",
      "  model.layers.9: 1\n",
      "  model.layers.10: 1\n",
      "  model.layers.11: 1\n",
      "  model.layers.12: 1\n",
      "  model.layers.13: 1\n",
      "  model.layers.14: 1\n",
      "  model.layers.15: 1\n",
      "  model.layers.16: 1\n",
      "  model.layers.17: 1\n",
      "  model.layers.18: 1\n",
      "  model.layers.19: 1\n",
      "  model.layers.20: 1\n",
      "  model.layers.21: 1\n",
      "  model.layers.22: 1\n",
      "  model.layers.23: 1\n",
      "  model.layers.24: 1\n",
      "  model.layers.25: 1\n",
      "  model.layers.26: 1\n",
      "  model.layers.27: 1\n",
      "  model.layers.28: 1\n",
      "  model.layers.29: 1\n",
      "  model.layers.30: 1\n",
      "  model.layers.31: 1\n",
      "  model.norm: 1\n",
      "Loaded 555 keywords for video domain\n",
      "Loaded 390 keywords for music domain\n",
      "Loaded 930 keywords for city domain\n",
      "处理音频:   0%|                                         | 0/378 [00:00<?, ?it/s]/home/v2129375/asr_biasing/asr/phi4_keywords.py:212: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=True):\n",
      "/home/v2129375/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "处理音频: 100%|███████████████████████████████| 378/378 [04:53<00:00,  1.29it/s]\n",
      "\n",
      "开始评估ASR结果...\n",
      "\n",
      "错误识别的样本:\n",
      "原始文本: 红日\n",
      "识别结果: 同日\n",
      "关键词: 红日\n",
      "---\n",
      "原始文本: 十万个为什么\n",
      "识别结果: 问个为什么\n",
      "关键词: 十万个为什么\n",
      "---\n",
      "原始文本: 我想看楚乔传\n",
      "识别结果: 我想看处巧传\n",
      "关键词: 楚乔传\n",
      "---\n",
      "原始文本: 猪小妹\n",
      "识别结果: 朱小妹\n",
      "关键词: 猪小妹\n",
      "---\n",
      "原始文本: 我想看汪汪队\n",
      "识别结果: 我想看 wong wong 队\n",
      "关键词: 汪汪队\n",
      "---\n",
      "原始文本: 小乐播放数鸭子\n",
      "识别结果: 小乐播放数个鸭子\n",
      "关键词: 数鸭子\n",
      "---\n",
      "原始文本: 播放艾利之书\n",
      "识别结果: 播放安利之书\n",
      "关键词: 艾利之书\n",
      "---\n",
      "原始文本: 我要看千与千寻\n",
      "识别结果: 我要看千里千寻\n",
      "关键词: 千与千寻\n",
      "---\n",
      "原始文本: 放妮妮猫儿歌上学歌\n",
      "识别结果: 放妮妮猫二哥上学歌\n",
      "关键词: 妮妮猫儿歌上学歌\n",
      "---\n",
      "原始文本: 播放猩球崛起三\n",
      "识别结果: 播放星球大战三\n",
      "关键词: 猩球崛起三\n",
      "---\n",
      "原始文本: 世上只有妈妈好\n",
      "识别结果: 四川只有妈妈好\n",
      "关键词: 世上只有妈妈好\n",
      "---\n",
      "原始文本: 播放艾利之书\n",
      "识别结果: 播放爱立志书\n",
      "关键词: 艾利之书\n",
      "---\n",
      "原始文本: 小飞侠\n",
      "识别结果: 小飞象玩这个那个飞机玩很好\n",
      "关键词: 小飞侠\n",
      "---\n",
      "原始文本: 放白雪公主\n",
      "识别结果: 放白鞋公主\n",
      "关键词: 白雪公主\n",
      "---\n",
      "原始文本: 放小白兔白又白\n",
      "识别结果: 唱一下白兔白兔白\n",
      "关键词: 小白兔白又白\n",
      "---\n",
      "原始文本: 蒙面唱将猜猜猜第二季\n",
      "识别结果: 蒙面唱相猜猜猜第二季\n",
      "关键词: 蒙面唱将猜猜猜\n",
      "---\n",
      "原始文本: 播放超级会飞侠第三季\n",
      "识别结果: 播放超级灰飞侠第三季\n",
      "关键词: 超级会飞侠\n",
      "---\n",
      "原始文本: 播放聪明的一休第二十二集\n",
      "识别结果: 播放聪明的一宿第二十二集\n",
      "关键词: 聪明的一休\n",
      "---\n",
      "原始文本: 播放巧虎来啦\n",
      "识别结果: 播放巧虎来了\n",
      "关键词: 巧虎来啦\n",
      "---\n",
      "原始文本: 请放一首张明敏的我的中国心\n",
      "识别结果: 请放一首张敏宁的我的中国心\n",
      "关键词: 张明敏\n",
      "---\n",
      "原始文本: 唱小蓓蕾儿儿歌\n",
      "识别结果: 唱小贝勒儿歌\n",
      "关键词: 小蓓蕾\n",
      "---\n",
      "原始文本: 点首歌爱我你就抱抱我林妙可的\n",
      "识别结果: 点首歌爱我你就抱抱我林苗可的\n",
      "关键词: 林妙可\n",
      "---\n",
      "原始文本: 梦然唱的没有你陪伴真的好孤单\n",
      "识别结果: 梦来唱的没有你陪伴真的好孤单\n",
      "关键词: 梦然\n",
      "---\n",
      "原始文本: 云菲菲的都市情缘\n",
      "识别结果: 云飞飞的都市情缘\n",
      "关键词: 云菲菲\n",
      "---\n",
      "原始文本: 祁隆的歌爰的世界只有你\n",
      "识别结果: 启龙的歌爱的世界只有你\n",
      "关键词: 祁隆\n",
      "---\n",
      "原始文本: 樊竹青的歌曲\n",
      "识别结果: 樊猪青的歌曲\n",
      "关键词: 樊竹青\n",
      "---\n",
      "原始文本: 唱一首王蓉的小鸡小鸡\n",
      "识别结果: 唱一首巴厘岛小鸡小鸡\n",
      "关键词: 王蓉\n",
      "---\n",
      "原始文本: 潘玮柏的\n",
      "识别结果: 听潘伟博的\n",
      "关键词: 潘玮柏\n",
      "---\n",
      "原始文本: 田馥甄的小幸运\n",
      "识别结果: 田馥珍的小幸运\n",
      "关键词: 田馥甄\n",
      "---\n",
      "原始文本: 黄蓉小鸡小鸡\n",
      "识别结果: 黄龙小鸡小鸡\n",
      "关键词: 黄蓉\n",
      "---\n",
      "原始文本: 汪苏泷那个男孩\n",
      "识别结果: 公子龙那个男孩\n",
      "关键词: 汪苏泷\n",
      "---\n",
      "原始文本: 来一首王绎龙的摇摆哥\n",
      "识别结果: 来一首王毅龙的摇摆歌\n",
      "关键词: 王绎龙\n",
      "---\n",
      "原始文本: 小乐明天杭州天气怎么样\n",
      "识别结果: 小乐明天安家天气怎么样\n",
      "关键词: 杭州\n",
      "---\n",
      "原始文本: 鄂州\n",
      "识别结果: 我们走了\n",
      "关键词: 鄂州\n",
      "---\n",
      "原始文本: 嗯现在深深圳天气怎么样\n",
      "识别结果: 韩红\n",
      "关键词: 深深圳\n",
      "---\n",
      "原始文本: 北京后天的天气怎么样\n",
      "识别结果: 三十三\n",
      "关键词: 北京\n",
      "---\n",
      "原始文本: 我要看兰州天气\n",
      "识别结果: 我要看南通的天气\n",
      "关键词: 兰州\n",
      "---\n",
      "原始文本: 阜新今天天气\n",
      "识别结果: 福兴今天天气\n",
      "关键词: 阜新\n",
      "---\n",
      "原始文本: 珠海\n",
      "识别结果: 朱海\n",
      "关键词: 珠海\n",
      "---\n",
      "原始文本: 绥化\n",
      "识别结果: 谁话\n",
      "关键词: 绥化\n",
      "---\n",
      "原始文本: 长沙后天的天气\n",
      "识别结果: 查查后天的天气\n",
      "关键词: 长沙\n",
      "---\n",
      "原始文本: 今天阜新的天气\n",
      "识别结果: 今天馀新的天气\n",
      "关键词: 阜新\n",
      "---\n",
      "原始文本: 亳州的天气怎么样\n",
      "识别结果: 谢谢\n",
      "关键词: 亳州\n",
      "---\n",
      "\n",
      "总体结果:\n",
      "CER: 0.0980\n",
      "Keyword WER: 0.1138\n",
      "\n",
      "各类别结果:\n",
      "\n",
      "类别: video\n",
      "样本数: 157\n",
      "CER: 0.1113\n",
      "Keyword WER: 0.1210\n",
      "\n",
      "类别: music\n",
      "样本数: 101\n",
      "CER: 0.0678\n",
      "Keyword WER: 0.1287\n",
      "\n",
      "类别: city\n",
      "样本数: 120\n",
      "CER: 0.1060\n",
      "Keyword WER: 0.0917\n",
      "\n",
      "结果已保存到: asr/exp/new.json\n",
      "第 3/3 次评估完成\n",
      "\n",
      "所有微调任务已完成！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 定义要尝试的参数\n",
    "num_sentences_list = [200, 500, 1500]  # 句子数量列表\n",
    "output_dir_list = [\"asr/model/200aishell1p2keywords\", \"asr/model/500aishell1p2keywords\", \"asr/model/1500aishell1p2keywords\"]  # 输出目录列表\n",
    "\n",
    "# 循环执行不同参数组合的微调脚本\n",
    "for i, (num_sentences, output_dir) in enumerate(zip(num_sentences_list, output_dir_list)):\n",
    "    print(f\"开始执行第 {i+1}/{len(num_sentences_list)} 次微调任务\")\n",
    "    print(f\"参数: num_sentences={num_sentences}, output_dir={output_dir}\")\n",
    "    \n",
    "    # 构建完整命令\n",
    "    command = f\"python /home/v2129375/asr_biasing/asr/aishell_finetune/finetune_aishell_keywords.py --num_sentences {num_sentences} --output_dir {output_dir}\"\n",
    "    command2 = f\"python /home/v2129375/asr_biasing/asr/phi4_keywords.py --model_path {output_dir} --output asr/exp/{os.path.basename({output_dir})}.csv\"\n",
    "\n",
    "    # 执行命令\n",
    "    print(f\"执行命令: {command}\")\n",
    "    !{command}\n",
    "    print(f\"第 {i+1}/{len(num_sentences_list)} 次微调任务完成\\n\")\n",
    "    !{command2}\n",
    "    print(f\"第 {i+1}/{len(num_sentences_list)} 次评估完成\\n\")\n",
    "print(\"所有微调任务已完成！\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
