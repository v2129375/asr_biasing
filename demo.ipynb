{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/v2129375/asr_biasing\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/v2129375/anaconda3/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:590: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "/root/.cache/huggingface/modules/transformers_modules/microsoft/Phi-4-multimodal-instruct/33e62acdd07cd7d6635badd529aa0a3467bb9c6a/speech_conformer_encoder.py:2774: FutureWarning: Please specify CheckpointImpl.NO_REENTRANT as CheckpointImpl.REENTRANT will soon be removed as the default and eventually deprecated.\n",
      "  lambda i: encoder_checkpoint_wrapper(\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:01<00:00,  2.44it/s]\n",
      "数据集中发现的领域: ['video' 'city' 'music']\n",
      "Loaded 555 keywords for video domain\n",
      "Loaded 390 keywords for music domain\n",
      "Loaded 930 keywords for city domain\n",
      "数据集中发现的领域: ['video' 'music' 'city']\n",
      "Loaded 555 keywords for video domain\n",
      "Loaded 390 keywords for music domain\n",
      "Loaded 930 keywords for city domain\n",
      "Train dataset size: 1311\n",
      "Eval dataset size: 200\n",
      "Keywords directory: data/catslu\n",
      "training on 1 GPUs\n",
      "running eval:   0%|                                     | 0/200 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/v2129375/anaconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "running eval: 100%|███████████████████████████| 200/200 [01:00<00:00,  3.28it/s]\n",
      "Overall CER: 0.6847\n",
      "Overall Keyword Error Rate: 0.1550\n",
      "\n",
      "按领域统计:\n",
      "VIDEO - Count: 73, CER: 1.4016\n",
      "  Keyword Error Rate: 0.1781 (13/73)\n",
      "MUSIC - Count: 63, CER: 0.2283\n",
      "  Keyword Error Rate: 0.1905 (12/63)\n",
      "CITY - Count: 64, CER: 0.3162\n",
      "  Keyword Error Rate: 0.0938 (6/64)\n",
      "\n",
      "错误识别的样本:\n",
      "领域: video\n",
      "原始文本: 播放艾利之书\n",
      "识别结果: 播放爱丽之书。\n",
      "关键词: 艾利之书\n",
      "---\n",
      "领域: city\n",
      "原始文本: 江门天气\n",
      "识别结果: 厦门天气。\n",
      "关键词: 江门\n",
      "---\n",
      "领域: music\n",
      "原始文本: 周璇夜上海\n",
      "识别结果: 周旋夜上海。\n",
      "关键词: 周璇\n",
      "---\n",
      "领域: music\n",
      "原始文本: 放一首刘欢的青花瓷\n",
      "识别结果: 唱一首刘芳的青花瓷。\n",
      "关键词: 刘欢\n",
      "---\n",
      "领域: city\n",
      "原始文本: 上海明天的天气情况\n",
      "识别结果: 你是谁？\n",
      "关键词: 上海\n",
      "---\n",
      "领域: video\n",
      "原始文本: 播放小星星\n",
      "识别结果: 黄梅戏， 辛特勒的名单， 指环王三王者无敌， 三字经， 张大千， 鸳鸯蝴蝶梦， 李茶的姑妈， 桂河桥， 米奇妙妙屋， 明月几时有。\n",
      "关键词: 小星星\n",
      "---\n",
      "领域: music\n",
      "原始文本: 奇迹再现毛毛唱的\n",
      "识别结果: 奇迹在线productive=1的版本。\n",
      "关键词: 毛毛\n",
      "---\n",
      "领域: video\n",
      "原始文本: 海底小纵队\n",
      "识别结果: 海底捞, 大脑越狱, 爱我你就抱抱我, 唐人街探案, 速度与激情, 日瓦戈医生, 三个和尚, 育婴奇谭, 哥斯拉, 火影忍者\n",
      "关键词: 海底小纵队\n",
      "---\n",
      "领域: music\n",
      "原始文本: 李行亮的愿得一人心\n",
      "识别结果: 你贤淑的愿得一人心。\n",
      "关键词: 李行亮\n",
      "---\n",
      "领域: video\n",
      "原始文本: 嗯冰雪奇缘\n",
      "识别结果: 西线无战事, 背叛的街角, 天神之国, 幻想曲, 无因的反叛, 苏菲亚小公主, 瓢虫雷迪, 大阅兵, 张博士, 祝福\n",
      "关键词: 冰雪奇缘\n",
      "---\n",
      "CER before finetuning: 0.6846866466866467\n",
      "Keyword Error Rate before finetuning: 0.155\n",
      "  0%|                                                  | 0/1311 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "{'loss': 3.3987, 'grad_norm': 39.25, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.01}\n",
      "{'loss': 1.9356, 'grad_norm': 21.25, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.02}\n",
      "{'loss': 0.3353, 'grad_norm': 0.30078125, 'learning_rate': 2.4e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1395, 'grad_norm': 0.09326171875, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.03}\n",
      "{'loss': 0.193, 'grad_norm': 2.828125, 'learning_rate': 4e-05, 'epoch': 0.04}   \n",
      "{'loss': 0.269, 'grad_norm': 0.0181884765625, 'learning_rate': 3.968279143536876e-05, 'epoch': 0.05}\n",
      "{'loss': 0.905, 'grad_norm': 18.625, 'learning_rate': 3.936558287073751e-05, 'epoch': 0.05}\n",
      "{'loss': 0.54, 'grad_norm': 21.0, 'learning_rate': 3.904837430610627e-05, 'epoch': 0.06}\n",
      "{'loss': 0.3094, 'grad_norm': 12.3125, 'learning_rate': 3.873116574147502e-05, 'epoch': 0.07}\n",
      "{'loss': 0.1747, 'grad_norm': 5.4375, 'learning_rate': 3.841395717684378e-05, 'epoch': 0.08}\n",
      "{'loss': 0.696, 'grad_norm': 36.75, 'learning_rate': 3.809674861221253e-05, 'epoch': 0.08}\n",
      "{'loss': 0.1055, 'grad_norm': 0.049072265625, 'learning_rate': 3.7779540047581286e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0143, 'grad_norm': 0.09765625, 'learning_rate': 3.7462331482950045e-05, 'epoch': 0.1}\n",
      "{'loss': 0.2073, 'grad_norm': 2.625, 'learning_rate': 3.71451229183188e-05, 'epoch': 0.11}\n",
      "{'loss': 0.3052, 'grad_norm': 19.75, 'learning_rate': 3.682791435368755e-05, 'epoch': 0.11}\n",
      "{'loss': 0.1766, 'grad_norm': 0.0031585693359375, 'learning_rate': 3.651070578905631e-05, 'epoch': 0.12}\n",
      "{'loss': 0.3591, 'grad_norm': 0.020263671875, 'learning_rate': 3.619349722442506e-05, 'epoch': 0.13}\n",
      "{'loss': 0.7902, 'grad_norm': 1.15625, 'learning_rate': 3.587628865979382e-05, 'epoch': 0.14}\n",
      "{'loss': 0.3279, 'grad_norm': 0.00848388671875, 'learning_rate': 3.555908009516257e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0482, 'grad_norm': 0.0034027099609375, 'learning_rate': 3.524187153053133e-05, 'epoch': 0.15}\n",
      "{'loss': 0.04, 'grad_norm': 7.875, 'learning_rate': 3.492466296590008e-05, 'epoch': 0.16}\n",
      "{'loss': 0.1902, 'grad_norm': 29.375, 'learning_rate': 3.460745440126884e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0143, 'grad_norm': 0.024169921875, 'learning_rate': 3.429024583663759e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0595, 'grad_norm': 6.0625, 'learning_rate': 3.3973037272006345e-05, 'epoch': 0.18}\n",
      "{'loss': 0.1828, 'grad_norm': 0.1669921875, 'learning_rate': 3.3655828707375104e-05, 'epoch': 0.19}\n",
      "{'loss': 0.1325, 'grad_norm': 0.119140625, 'learning_rate': 3.333862014274386e-05, 'epoch': 0.2}\n",
      "{'loss': 0.1342, 'grad_norm': 9.125, 'learning_rate': 3.302141157811261e-05, 'epoch': 0.21}\n",
      "{'loss': 0.3132, 'grad_norm': 10.125, 'learning_rate': 3.270420301348137e-05, 'epoch': 0.21}\n",
      "{'loss': 0.4761, 'grad_norm': 37.75, 'learning_rate': 3.238699444885012e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0054, 'grad_norm': 3.09375, 'learning_rate': 3.206978588421888e-05, 'epoch': 0.23}\n",
      "{'loss': 0.1863, 'grad_norm': 1.125, 'learning_rate': 3.175257731958763e-05, 'epoch': 0.24}\n",
      "{'loss': 0.1057, 'grad_norm': 23.625, 'learning_rate': 3.1435368754956386e-05, 'epoch': 0.24}\n",
      "{'loss': 0.1316, 'grad_norm': 0.048828125, 'learning_rate': 3.111816019032514e-05, 'epoch': 0.25}\n",
      "{'loss': 0.08, 'grad_norm': 3.609375, 'learning_rate': 3.08009516256939e-05, 'epoch': 0.26}\n",
      "{'loss': 0.1341, 'grad_norm': 0.0159912109375, 'learning_rate': 3.048374306106265e-05, 'epoch': 0.27}\n",
      "{'loss': 0.13, 'grad_norm': 0.0380859375, 'learning_rate': 3.0166534496431407e-05, 'epoch': 0.27}\n",
      "{'loss': 0.3858, 'grad_norm': 0.00087738037109375, 'learning_rate': 2.9849325931800163e-05, 'epoch': 0.28}\n",
      "{'loss': 0.0621, 'grad_norm': 0.095703125, 'learning_rate': 2.953211736716892e-05, 'epoch': 0.29}\n",
      "{'loss': 0.1694, 'grad_norm': 0.0277099609375, 'learning_rate': 2.921490880253767e-05, 'epoch': 0.3}\n",
      "{'loss': 0.338, 'grad_norm': 0.384765625, 'learning_rate': 2.8897700237906425e-05, 'epoch': 0.31}\n",
      "{'loss': 0.1906, 'grad_norm': 0.053955078125, 'learning_rate': 2.858049167327518e-05, 'epoch': 0.31}\n",
      "{'loss': 0.3139, 'grad_norm': 0.01507568359375, 'learning_rate': 2.8263283108643937e-05, 'epoch': 0.32}\n",
      "{'loss': 0.1351, 'grad_norm': 19.125, 'learning_rate': 2.794607454401269e-05, 'epoch': 0.33}\n",
      "{'loss': 0.0852, 'grad_norm': 0.0103759765625, 'learning_rate': 2.7628865979381445e-05, 'epoch': 0.34}\n",
      "{'loss': 0.0947, 'grad_norm': 1.3359375, 'learning_rate': 2.73116574147502e-05, 'epoch': 0.34}\n",
      "{'loss': 0.115, 'grad_norm': 0.010498046875, 'learning_rate': 2.6994448850118958e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0681, 'grad_norm': 10.5625, 'learning_rate': 2.667724028548771e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0945, 'grad_norm': 0.046142578125, 'learning_rate': 2.6360031720856466e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0924, 'grad_norm': 0.00148773193359375, 'learning_rate': 2.6042823156225222e-05, 'epoch': 0.37}\n",
      "{'loss': 0.1776, 'grad_norm': 20.5, 'learning_rate': 2.572561459159398e-05, 'epoch': 0.38}\n",
      "{'loss': 0.051, 'grad_norm': 3.03125, 'learning_rate': 2.5408406026962728e-05, 'epoch': 0.39}\n",
      "{'loss': 0.0753, 'grad_norm': 0.0269775390625, 'learning_rate': 2.5091197462331484e-05, 'epoch': 0.4}\n",
      "{'loss': 0.2127, 'grad_norm': 0.1767578125, 'learning_rate': 2.477398889770024e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0316, 'grad_norm': 2.390625, 'learning_rate': 2.4456780333068996e-05, 'epoch': 0.41}\n",
      "{'loss': 0.0358, 'grad_norm': 9.8125, 'learning_rate': 2.413957176843775e-05, 'epoch': 0.42}\n",
      "{'loss': 0.0896, 'grad_norm': 0.091796875, 'learning_rate': 2.3822363203806505e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0917, 'grad_norm': 20.0, 'learning_rate': 2.350515463917526e-05, 'epoch': 0.43}\n",
      "{'loss': 0.148, 'grad_norm': 0.033203125, 'learning_rate': 2.3187946074544017e-05, 'epoch': 0.44}\n",
      "{'loss': 0.2426, 'grad_norm': 0.0020294189453125, 'learning_rate': 2.287073750991277e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0198, 'grad_norm': 0.0106201171875, 'learning_rate': 2.2553528945281525e-05, 'epoch': 0.46}\n",
      "{'loss': 0.1305, 'grad_norm': 0.0052490234375, 'learning_rate': 2.223632038065028e-05, 'epoch': 0.47}\n",
      "{'loss': 0.0094, 'grad_norm': 8.6875, 'learning_rate': 2.1919111816019037e-05, 'epoch': 0.47}\n",
      "{'loss': 0.1405, 'grad_norm': 23.625, 'learning_rate': 2.1601903251387787e-05, 'epoch': 0.48}\n",
      "{'loss': 0.1573, 'grad_norm': 0.04248046875, 'learning_rate': 2.1284694686756543e-05, 'epoch': 0.49}\n",
      "{'loss': 0.2219, 'grad_norm': 13.5, 'learning_rate': 2.09674861221253e-05, 'epoch': 0.5}\n",
      "{'loss': 0.5222, 'grad_norm': 19.25, 'learning_rate': 2.0650277557494055e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0615, 'grad_norm': 0.0022430419921875, 'learning_rate': 2.0333068992862808e-05, 'epoch': 0.51}\n",
      "{'loss': 0.0006, 'grad_norm': 0.07470703125, 'learning_rate': 2.0015860428231564e-05, 'epoch': 0.52}\n",
      "{'loss': 0.0103, 'grad_norm': 0.306640625, 'learning_rate': 1.969865186360032e-05, 'epoch': 0.53}\n",
      "{'loss': 0.0135, 'grad_norm': 0.73828125, 'learning_rate': 1.9381443298969072e-05, 'epoch': 0.53}\n",
      "{'loss': 0.002, 'grad_norm': 0.0035552978515625, 'learning_rate': 1.906423473433783e-05, 'epoch': 0.54}\n",
      "{'loss': 0.0428, 'grad_norm': 0.001190185546875, 'learning_rate': 1.8747026169706585e-05, 'epoch': 0.55}\n",
      "{'loss': 0.4868, 'grad_norm': 0.099609375, 'learning_rate': 1.8429817605075337e-05, 'epoch': 0.56}\n",
      "{'loss': 0.1115, 'grad_norm': 0.004730224609375, 'learning_rate': 1.8112609040444093e-05, 'epoch': 0.56}\n",
      "{'loss': 0.3145, 'grad_norm': 0.10986328125, 'learning_rate': 1.7795400475812846e-05, 'epoch': 0.57}\n",
      "{'loss': 0.076, 'grad_norm': 0.000827789306640625, 'learning_rate': 1.7478191911181602e-05, 'epoch': 0.58}\n",
      "{'loss': 0.034, 'grad_norm': 11.75, 'learning_rate': 1.7160983346550358e-05, 'epoch': 0.59}\n",
      "{'loss': 0.0178, 'grad_norm': 0.2216796875, 'learning_rate': 1.6843774781919114e-05, 'epoch': 0.59}\n",
      "{'loss': 0.2697, 'grad_norm': 3.265625, 'learning_rate': 1.6526566217287867e-05, 'epoch': 0.6}\n",
      "{'loss': 0.2163, 'grad_norm': 0.004669189453125, 'learning_rate': 1.6209357652656623e-05, 'epoch': 0.61}\n",
      "{'loss': 0.6878, 'grad_norm': 0.1767578125, 'learning_rate': 1.5892149088025375e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0546, 'grad_norm': 0.054931640625, 'learning_rate': 1.557494052339413e-05, 'epoch': 0.63}\n",
      "{'loss': 0.0701, 'grad_norm': 9.125, 'learning_rate': 1.5257731958762888e-05, 'epoch': 0.63}\n",
      "{'loss': 0.3542, 'grad_norm': 0.0751953125, 'learning_rate': 1.4940523394131644e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0994, 'grad_norm': 18.125, 'learning_rate': 1.4623314829500396e-05, 'epoch': 0.65}\n",
      "{'loss': 0.5784, 'grad_norm': 8.25, 'learning_rate': 1.4306106264869152e-05, 'epoch': 0.66}\n",
      "{'loss': 0.0009, 'grad_norm': 0.05615234375, 'learning_rate': 1.3988897700237907e-05, 'epoch': 0.66}\n",
      "{'loss': 0.1026, 'grad_norm': 0.052490234375, 'learning_rate': 1.3671689135606663e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0431, 'grad_norm': 0.004150390625, 'learning_rate': 1.3354480570975417e-05, 'epoch': 0.68}\n",
      "{'loss': 0.7602, 'grad_norm': 79.0, 'learning_rate': 1.3037272006344173e-05, 'epoch': 0.69}\n",
      "{'loss': 0.0294, 'grad_norm': 1.640625, 'learning_rate': 1.2720063441712926e-05, 'epoch': 0.69}\n",
      "{'loss': 0.1091, 'grad_norm': 0.0037384033203125, 'learning_rate': 1.2402854877081682e-05, 'epoch': 0.7}\n",
      "{'loss': 0.2946, 'grad_norm': 0.1572265625, 'learning_rate': 1.2085646312450436e-05, 'epoch': 0.71}\n",
      "{'loss': 0.1149, 'grad_norm': 0.2421875, 'learning_rate': 1.1768437747819192e-05, 'epoch': 0.72}\n",
      "{'loss': 0.1923, 'grad_norm': 3.46875, 'learning_rate': 1.1451229183187947e-05, 'epoch': 0.72}\n",
      "{'loss': 0.0024, 'grad_norm': 0.5390625, 'learning_rate': 1.1134020618556703e-05, 'epoch': 0.73}\n",
      "{'loss': 0.0601, 'grad_norm': 0.0250244140625, 'learning_rate': 1.0816812053925455e-05, 'epoch': 0.74}\n",
      "{'loss': 0.1131, 'grad_norm': 18.125, 'learning_rate': 1.0499603489294211e-05, 'epoch': 0.75}\n",
      "{'loss': 0.1888, 'grad_norm': 17.125, 'learning_rate': 1.0182394924662966e-05, 'epoch': 0.76}\n",
      "{'loss': 0.1804, 'grad_norm': 0.0013885498046875, 'learning_rate': 9.865186360031722e-06, 'epoch': 0.76}\n",
      "{'loss': 0.0021, 'grad_norm': 0.000244140625, 'learning_rate': 9.547977795400476e-06, 'epoch': 0.77}\n",
      "{'loss': 0.1511, 'grad_norm': 7.875, 'learning_rate': 9.230769230769232e-06, 'epoch': 0.78}\n",
      "{'loss': 0.032, 'grad_norm': 0.000789642333984375, 'learning_rate': 8.913560666137987e-06, 'epoch': 0.79}\n",
      "{'loss': 0.3127, 'grad_norm': 13.9375, 'learning_rate': 8.596352101506743e-06, 'epoch': 0.79}\n",
      "{'loss': 0.4632, 'grad_norm': 0.03369140625, 'learning_rate': 8.279143536875495e-06, 'epoch': 0.8}\n",
      "{'loss': 0.0661, 'grad_norm': 18.625, 'learning_rate': 7.961934972244251e-06, 'epoch': 0.81}\n",
      "{'loss': 0.0316, 'grad_norm': 0.40625, 'learning_rate': 7.644726407613006e-06, 'epoch': 0.82}\n",
      "{'loss': 0.063, 'grad_norm': 14.1875, 'learning_rate': 7.327517842981761e-06, 'epoch': 0.82}\n",
      "{'loss': 0.0403, 'grad_norm': 13.125, 'learning_rate': 7.010309278350515e-06, 'epoch': 0.83}\n",
      "{'loss': 0.0655, 'grad_norm': 0.006256103515625, 'learning_rate': 6.693100713719271e-06, 'epoch': 0.84}\n",
      "{'loss': 0.0178, 'grad_norm': 0.0023193359375, 'learning_rate': 6.375892149088026e-06, 'epoch': 0.85}\n",
      "{'loss': 0.0131, 'grad_norm': 0.07421875, 'learning_rate': 6.05868358445678e-06, 'epoch': 0.85}\n",
      "{'loss': 0.4224, 'grad_norm': 20.25, 'learning_rate': 5.741475019825535e-06, 'epoch': 0.86}\n",
      "{'loss': 0.3154, 'grad_norm': 0.0086669921875, 'learning_rate': 5.424266455194291e-06, 'epoch': 0.87}\n",
      "{'loss': 0.5952, 'grad_norm': 0.0020294189453125, 'learning_rate': 5.107057890563045e-06, 'epoch': 0.88}\n",
      "{'loss': 0.1607, 'grad_norm': 0.08642578125, 'learning_rate': 4.789849325931801e-06, 'epoch': 0.88}\n",
      "{'loss': 0.0826, 'grad_norm': 0.0027313232421875, 'learning_rate': 4.472640761300555e-06, 'epoch': 0.89}\n",
      "{'loss': 0.0003, 'grad_norm': 0.006256103515625, 'learning_rate': 4.1554321966693106e-06, 'epoch': 0.9}\n",
      "{'loss': 0.4977, 'grad_norm': 0.00238037109375, 'learning_rate': 3.838223632038066e-06, 'epoch': 0.91}\n",
      "{'loss': 0.245, 'grad_norm': 0.0361328125, 'learning_rate': 3.5210150674068206e-06, 'epoch': 0.92}\n",
      "{'loss': 0.7206, 'grad_norm': 0.058837890625, 'learning_rate': 3.2038065027755754e-06, 'epoch': 0.92}\n",
      "{'loss': 0.2706, 'grad_norm': 22.125, 'learning_rate': 2.8865979381443297e-06, 'epoch': 0.93}\n",
      "{'loss': 0.0682, 'grad_norm': 0.002593994140625, 'learning_rate': 2.569389373513085e-06, 'epoch': 0.94}\n",
      "{'loss': 0.0268, 'grad_norm': 0.01385498046875, 'learning_rate': 2.25218080888184e-06, 'epoch': 0.95}\n",
      "{'loss': 0.1336, 'grad_norm': 0.00054168701171875, 'learning_rate': 1.934972244250595e-06, 'epoch': 0.95}\n",
      "{'loss': 0.5257, 'grad_norm': 22.5, 'learning_rate': 1.61776367961935e-06, 'epoch': 0.96}\n",
      "{'loss': 0.2909, 'grad_norm': 0.263671875, 'learning_rate': 1.300555114988105e-06, 'epoch': 0.97}\n",
      "{'loss': 0.1028, 'grad_norm': 0.0023040771484375, 'learning_rate': 9.833465503568597e-07, 'epoch': 0.98}\n",
      "{'loss': 0.0336, 'grad_norm': 0.00146484375, 'learning_rate': 6.661379857256146e-07, 'epoch': 0.98}\n",
      "{'loss': 0.6664, 'grad_norm': 0.0140380859375, 'learning_rate': 3.489294210943696e-07, 'epoch': 0.99}\n",
      "{'loss': 0.0663, 'grad_norm': 0.1201171875, 'learning_rate': 3.1720856463124506e-08, 'epoch': 1.0}\n",
      "{'train_runtime': 209.0122, 'train_samples_per_second': 6.272, 'train_steps_per_second': 6.272, 'train_loss': 0.23055286875969724, 'epoch': 1.0}\n",
      "100%|███████████████████████████████████████| 1311/1311 [03:29<00:00,  6.27it/s]\n",
      "/home/v2129375/anaconda3/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:590: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n",
      "/root/.cache/huggingface/modules/transformers_modules/speech_conformer_encoder.py:2774: FutureWarning: Please specify CheckpointImpl.NO_REENTRANT as CheckpointImpl.REENTRANT will soon be removed as the default and eventually deprecated.\n",
      "  lambda i: encoder_checkpoint_wrapper(\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:00<00:00,  5.81it/s]\n",
      "running eval:   0%|                                     | 0/200 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/v2129375/anaconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "running eval: 100%|███████████████████████████| 200/200 [00:45<00:00,  4.36it/s]\n",
      "Overall CER: 0.0584\n",
      "Overall Keyword Error Rate: 0.0850\n",
      "\n",
      "按领域统计:\n",
      "VIDEO - Count: 73, CER: 0.0648\n",
      "  Keyword Error Rate: 0.0959 (7/73)\n",
      "MUSIC - Count: 63, CER: 0.0563\n",
      "  Keyword Error Rate: 0.1111 (7/63)\n",
      "CITY - Count: 64, CER: 0.0530\n",
      "  Keyword Error Rate: 0.0469 (3/64)\n",
      "\n",
      "错误识别的样本:\n",
      "领域: music\n",
      "原始文本: 周璇夜上海\n",
      "识别结果: 周旋夜上海\n",
      "关键词: 周璇\n",
      "---\n",
      "领域: city\n",
      "原始文本: 上海明天的天气情况\n",
      "识别结果: 你是谁\n",
      "关键词: 上海\n",
      "---\n",
      "领域: video\n",
      "原始文本: 海底小纵队\n",
      "识别结果: 海底捞\n",
      "关键词: 海底小纵队\n",
      "---\n",
      "领域: music\n",
      "原始文本: 李行亮的愿得一人心\n",
      "识别结果: 你贤亮的愿得一人心\n",
      "关键词: 李行亮\n",
      "---\n",
      "领域: video\n",
      "原始文本: 嗯冰雪奇缘\n",
      "识别结果: 嗯冰淇淋\n",
      "关键词: 冰雪奇缘\n",
      "---\n",
      "领域: music\n",
      "原始文本: 迪克牛仔有多少爱可以重来\n",
      "识别结果: 迪克游仔有多少爱可以重来\n",
      "关键词: 迪克牛仔\n",
      "---\n",
      "领域: music\n",
      "原始文本: 樊竹青的歌曲\n",
      "识别结果: 樊祖清的歌曲\n",
      "关键词: 樊竹青\n",
      "---\n",
      "领域: video\n",
      "原始文本: 儿歌就行\n",
      "识别结果: 点点儿多就行\n",
      "关键词: 儿歌\n",
      "---\n",
      "领域: music\n",
      "原始文本: 邓丽君的甜蜜蜜\n",
      "识别结果: 任丽君的甜蜜蜜\n",
      "关键词: 邓丽君\n",
      "---\n",
      "领域: city\n",
      "原始文本: 阜新天气\n",
      "识别结果: 复兴天气\n",
      "关键词: 阜新\n",
      "---\n",
      "CER after finetuning: 0.05837703962703961\n",
      "Keyword Error Rate after finetuning: 0.085\n"
     ]
    }
   ],
   "source": [
    "!/home/v2129375/anaconda3/bin/python /home/v2129375/asr_biasing/asr/finetune/finetune_speech_asr_keywords.py \\\n",
    "    --use_flash_attention "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
